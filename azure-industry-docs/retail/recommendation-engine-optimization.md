---
title: レコメンダー システムと R のアルゴリズムの Azure での再利用
author: kbaroni
ms.author: kbaroni
ms.date: 11/20/2019
ms.topic: article
ms.service: industry
description: R 言語で記述されたレコメンデーション アプリを再利用および最適化する方法。 Azure VM 上の Machine Learning Server に依存します。
ms.openlocfilehash: c5c35de681abc52641952f8bc9e95095b9d99d97
ms.sourcegitcommit: b8f9ccc4e4453d6912b05cdd6cf04276e13d7244
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/21/2019
ms.locfileid: "74263492"
---
# <a name="optimize-and-reuse-an-existing-recommendation-system"></a><span data-ttu-id="c5d7b-104">既存のレコメンデーション システムの最適化と再利用</span><span class="sxs-lookup"><span data-stu-id="c5d7b-104">Optimize and reuse an existing recommendation system</span></span>  

<span data-ttu-id="c5d7b-105">このドキュメントでは、R で記述された既存のレコメンデーション システムを正しく再利用および改善するプロセスについて説明します。このための鍵は、Microsoft Machine Learning Server に組み込まれた MicrosoftML ライブラリと RevoScaleR ライブラリの並列性でした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-105">This document describes the process of successfully reusing and improving an existing recommendation system written in R. The key to this was the parallelism of the MicrosoftML and RevoScaleR libraries built into Microsoft Machine Learning Server.</span></span>

## <a name="recommendation-systems-and-r"></a><span data-ttu-id="c5d7b-106">レコメンデーション システムと R</span><span class="sxs-lookup"><span data-stu-id="c5d7b-106">Recommendation systems and R</span></span>

<span data-ttu-id="c5d7b-107">小売業者にとって、消費者の好みと購買履歴を理解することは競争上の強みです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-107">For a retailer, understanding consumer preferences and purchasing history is a competitive advantage.</span></span> <span data-ttu-id="c5d7b-108">小売業者は長年にわたり、そのようなデータを機械学習と組み合わせて使用することで、消費者に関連する製品を識別したり、パーソナライズされたショッピング体験を提供したりしてきました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-108">Retailers have been using such data for years, in combination with machine learning, to identify products relevant to the consumer and deliver a personalized shopping experience.</span></span> <span data-ttu-id="c5d7b-109">このアプローチは**製品のレコメンデーション**と呼ばれ、小売業者にとって大きな収入の流れを生み出します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-109">The approach is called **product recommendation** and it generates a significant revenue stream for retailers.</span></span> <span data-ttu-id="c5d7b-110">レコメンデーション システムは、次のような疑問への答えを得るために役立ちます。*この人は次にどの映画を見るか?この顧客はどのような追加サービスに興味を持ちそうか?この顧客はどこで休暇を過ごしたいか?*</span><span class="sxs-lookup"><span data-stu-id="c5d7b-110">Recommendation systems help answer questions like: *What movie will this person watch next? What additional services is this customer likely to be interested in? Where will this customer want to vacation?*</span></span>
<span data-ttu-id="c5d7b-111">ある最近の顧客は、次のことを知りたがっていました。*消費者 (サブスクライバー) は契約を更新するだろうか?*</span><span class="sxs-lookup"><span data-stu-id="c5d7b-111">A recent customer wanted to know: *Will consumers (subscribers) renew their contracts?*</span></span> <span data-ttu-id="c5d7b-112">その顧客は、サブスクライバーが契約を更新する確率を予測する既存のレコメンデーション モデルを持っていました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-112">The customer had an existing recommendation model that would forecast the probability of a subscriber renewing a contract.</span></span> <span data-ttu-id="c5d7b-113">予測が生成されたら、追加の処理を適用して応答をはい、いいえ、可能性ありのいずれかに分類していました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-113">Once the forecast was generated, additional processing was applied to classify a response into a yes, no, or maybe.</span></span> <span data-ttu-id="c5d7b-114">その後、モデルの応答はコール センターのビジネス プロセスに統合されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-114">The model response was then integrated into a call center business process.</span></span> <span data-ttu-id="c5d7b-115">そのプロセスによって、サービス エージェントはパーソナライズされたレコメンデーションを消費者に提供することができました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-115">That process enabled a service agent to deliver a personalized recommendation to the consumer.</span></span>  
<span data-ttu-id="c5d7b-116">この顧客の初期の分析製品の多くは、レコメンデーション システムの中核の機械学習モデルを含め、[プログラミング言語 R](https://docs.microsoft.com/machine-learning-server/rebranding-microsoft-r-server) で構築されていました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-116">Many of this customer’s early analytic products were built in the [programming language R](https://docs.microsoft.com/machine-learning-server/rebranding-microsoft-r-server), including the machine learning model at the core of their recommendation system.</span></span> <span data-ttu-id="c5d7b-117">サブスクライバーの増加に伴い、データおよび計算の要件も高度化しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-117">As their subscriber base has grown, so have the data and compute requirements.</span></span> <span data-ttu-id="c5d7b-118">そのため今となっては、レコメンデーションのワークロードは非常に低速であり、処理が面倒です。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-118">So much so, the recommendation workload is now painfully slow and cumbersome to process.</span></span> <span data-ttu-id="c5d7b-119">最近は、分析製品戦略に Python が組み込まれるようになってきています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-119">Now Python is increasingly a part of their analytic product strategy.</span></span> <span data-ttu-id="c5d7b-120">しかし短期的には、R への投資を維持し、より効率的な開発とデプロイのプロセスを見つける必要があります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-120">But for the near term, they need to preserve their R investment and find a more efficient development and deployment process.</span></span> <span data-ttu-id="c5d7b-121">課題は、Azure の機能を使用して既存のアプローチを最適化することでした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-121">The challenge was to optimize the existing approach using capabilities in Azure.</span></span> <span data-ttu-id="c5d7b-122">私たちは、レコメンデーションのワークロードのための概念実証テクノロジ スタックを提供し、検証するタスクに着手しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-122">We embarked on a task to provide—and validate—a proof-of-concept technology stack for the recommendation workload.</span></span> <span data-ttu-id="c5d7b-123">ここでは、類似のプロジェクトで利用できる一般的なアプローチをまとめています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-123">Here we summarize a general approach that can be used for similar projects.</span></span>  

## <a name="design-goals"></a><span data-ttu-id="c5d7b-124">設計目標</span><span class="sxs-lookup"><span data-stu-id="c5d7b-124">Design goals</span></span>

<span data-ttu-id="c5d7b-125">重要な優先事項は、次のような強みを提供するために、モデルのワークフローを再設計および自動化することでした:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-125">A key priority was to redesign and automate the model workflow to provide several advantages:</span></span>

- <span data-ttu-id="c5d7b-126">モデル開発サイクルの迅速化とイノベーションまでの時間の短縮。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-126">Faster model development cycles and faster time-to-innovate.</span></span> <span data-ttu-id="c5d7b-127">データ準備とモデル開発のサイクルが効率的であれば、実験のボリュームを増加させることができます。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-127">When data preparation and model development cycles are efficient, the volume of experiments can increase.</span></span>  
- <span data-ttu-id="c5d7b-128">最新のデータに基づいて再トレーニングのサイクルをより頻繁に回すことで、より正確なモデル結果とより的確なレコメンデーションを得る。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-128">More accurate model results and better recommendations through more frequent retraining cycles on fresh data.</span></span>
- <span data-ttu-id="c5d7b-129">よりスケーラブルで、完全な運用環境で稼働する概念実証 (POC) の実装。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-129">A more scalable proof-of-concept (POC) implementation—one that would work in full production.</span></span>
- <span data-ttu-id="c5d7b-130">開発、テスト、デプロイ間のプロセスを自動化することで、運用開始までの期間を短縮。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-130">Faster time to production by automating the processes between development, test, and deployment.</span></span> <span data-ttu-id="c5d7b-131">自動化によって運用上のエラーや遅滞も削減します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-131">Automation also reduces operational errors and lag times.</span></span>  

## <a name="requirements"></a><span data-ttu-id="c5d7b-132">必要条件</span><span class="sxs-lookup"><span data-stu-id="c5d7b-132">Requirements</span></span>

<span data-ttu-id="c5d7b-133">ワークフローの再設計には次の要件がありました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-133">The workflow redesign had the following requirements:</span></span>

- <span data-ttu-id="c5d7b-134">チームの既存の R スキルと専門知識を活用する。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-134">Leverage the team’s existing R skills and expertise.</span></span>
- <span data-ttu-id="c5d7b-135">意味のある場面ではコードを再利用する。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-135">Reuse code where it made sense.</span></span>
- <span data-ttu-id="c5d7b-136">サブスクライバー データをデータベースに格納し、モデルのトレーニングと再トレーニングのプロセスに容易かつ迅速に統合する。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-136">Store subscriber data in a database to be easily and quickly integrated into the model training and retraining process.</span></span>
- <span data-ttu-id="c5d7b-137">モデルの再トレーニングとスコアリングを Web アプリのインターフェイスから呼び出す。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-137">Invoke model retraining and scoring through a web app interface.</span></span>
- <span data-ttu-id="c5d7b-138">Web フロントエンドでの認証に Azure Active Directory を使用する。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-138">Use Azure Active Directory for authentication on the web front end.</span></span>

## <a name="technology-stack"></a><span data-ttu-id="c5d7b-139">テクノロジ スタック</span><span class="sxs-lookup"><span data-stu-id="c5d7b-139">Technology stack</span></span>

<span data-ttu-id="c5d7b-140">このプロジェクトのパイプラインには複数のテクノロジとツールが必要であり、次の 4 つの領域が軸でした:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-140">The pipeline for this project required multiple technologies and tools and centered around four areas:</span></span>

1. <span data-ttu-id="c5d7b-141">サブスクライバー データの持続性とアクセシビリティ。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-141">Persistence and accessibility of subscriber data.</span></span>
2. <span data-ttu-id="c5d7b-142">モデルの開発、トレーニング、選択。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-142">Development, training, and selection of models.</span></span>  
3. <span data-ttu-id="c5d7b-143">モデル デプロイと運用化。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-143">Model deployment and operationalization.</span></span>
4. <span data-ttu-id="c5d7b-144">Web アプリケーションを使用してスコアリングとモデルの再トレーニングを呼び出すこと。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-144">Use of a web application to invoke scoring and model re-training.</span></span>

<span data-ttu-id="c5d7b-145">パイプライン図のテクノロジ構成要素については、以下で詳しく説明します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-145">The technology components in the pipeline diagram are discussed in more detail below.</span></span>

![最適化のアーキテクチャ](assets/recommendation-engine-optimization/recommendation-architecture.png)

### <a name="microsoft-machine-learning-server"></a><span data-ttu-id="c5d7b-147">Microsoft Machine Learning Server</span><span class="sxs-lookup"><span data-stu-id="c5d7b-147">Microsoft Machine Learning Server</span></span>

<span data-ttu-id="c5d7b-148">R ワークロードを選択する主な理由は、 **[RevoScaleR](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/revoscaler)** と **Microsoft ML** にあります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-148">The primary reason for selecting R workloads: **[RevoScaleR](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/revoscaler)** and **Microsoft ML**.</span></span> <span data-ttu-id="c5d7b-149">データをインポートしたり、分類モデルを作成したり、それらを運用環境にデプロイしたりするために、これらのパッケージに含まれる関数をコード全体で多用していました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-149">The functions included with these packages were used extensively throughout the code to import the data, create the classification models, and deploy them into production.</span></span>
<span data-ttu-id="c5d7b-150">それぞれ "開発" と "運用" のために構成された、Azure の 2 つの Linux 仮想マシンに MLS がデプロイされました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-150">MLS was deployed on two Linux virtual machines in Azure: one configured for “development” and one configured for “operations.”</span></span> <span data-ttu-id="c5d7b-151">開発 VM には、数百のモデルのトレーニングとテストを促進するために、より多くのメモリと処理能力がプロビジョニングされました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-151">The development VM was provisioned with significantly more memory and processing power to facilitate the training and testing of hundreds of models.</span></span> <span data-ttu-id="c5d7b-152">また、リモート ユーザーが RStudio IDE に容易にアクセスできるよう、RStudio Server をホストしていました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-152">It also hosted RStudio Server to provide easy access to an RStudio IDE for remote users.</span></span> <span data-ttu-id="c5d7b-153">運用サーバーはより小規模な VM 上に構成され、Web アプリケーションから REST API 経由で呼び出せる R モデルをホストするために必要な拡張機能を追加していました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-153">The operations server was configured on a smaller VM with the additional extensions necessary to host R models that were callable from a web application through REST APIs.</span></span>

### <a name="rstudio-server"></a><span data-ttu-id="c5d7b-154">RStudio Server</span><span class="sxs-lookup"><span data-stu-id="c5d7b-154">RStudio Server</span></span>

<span data-ttu-id="c5d7b-155">**[RStudio Server](https://www.rstudio.com/products/rstudio/#Server)** は、リモートまたはラップトップ クライアント用のブラウザー ベースのインターフェイスを提供する Linux アプリケーションです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-155">**[RStudio Server](https://www.rstudio.com/products/rstudio/#Server)** is a Linux application that provides a browser-based interface for remote or laptop clients.</span></span> <span data-ttu-id="c5d7b-156">ポート 8787 で実行され、Azure VM でネットワーク セキュリティ規則が作成されるとリモート接続が可能になります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-156">It runs on port 8787 and is available to remote connections once a network security rule is created on the Azure VM.</span></span> <span data-ttu-id="c5d7b-157">RStudio IDE を好むアナリストやデータ サイエンティストに、計算とメモリの容量が大きい仮想マシンへのアクセスを提供するための効率的なオプションです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-157">For analysts and data scientists who prefer the RStudio IDE, it can be an efficient option for providing access to virtual machine with a large compute and memory capacity.</span></span> <span data-ttu-id="c5d7b-158">ソース エディションと商用エディションの両方がダウンロード可能です。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-158">It is available for download in both source and commercial editions.</span></span>

### <a name="azure-sql-database"></a><span data-ttu-id="c5d7b-159">Azure SQL Database</span><span class="sxs-lookup"><span data-stu-id="c5d7b-159">Azure SQL Database</span></span>

<span data-ttu-id="c5d7b-160">サブスクライバー データは元々、500 人の一意なサブスクライバーの購買およびプリファレンス情報を、600 万行もの 1 つの巨大な .csv ファイルに格納するものでした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-160">Originally, the subscriber data was stored in one very large .csv file with 6 million rows of purchasing and preference information for 500 unique subscribers.</span></span> <span data-ttu-id="c5d7b-161">データをデータベースに格納することで、R 内からのデータ アクセスが高速化され、フィルターを適用した読み取りが可能になりました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-161">Storing the data in a database meant faster data access from within R and it would allow for filtered reads.</span></span> <span data-ttu-id="c5d7b-162">トレーニングまたは再トレーニングのためにデータ セット全体をインポートする必要がなくなります: データはデータベース ソースでサブスクライバーによってフィルタリングされ、データのインポートと処理に必要なリソースが大幅に削減されます。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-162">No longer would the entire data set need to be imported for training or retraining: data would be filtered by subscriber at the database source, significantly reducing the resources needed to import and process the data.</span></span>  
<span data-ttu-id="c5d7b-163">Azure には、マネージド クラウド データベースのオプションが複数あります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-163">There are several managed cloud database options in Azure.</span></span> <span data-ttu-id="c5d7b-164">[Azure SQL Database](https://docs.microsoft.com/azure/sql-database/) が選ばれた理由は、顧客が SQL Server に慣れ親しんでいたこと、そしてより重要な点として、将来的に SQL Server Machine Learning Services を Azure SQL Database にいっそう大規模に導入する計画があったことです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-164">[Azure SQL Database](https://docs.microsoft.com/azure/sql-database/) was selected because of the customer’s familiarity with SQL Server and—more importantly—future plans to introduce SQL Server Machine Learning Services on a broader scale to Azure SQL Database.</span></span> <span data-ttu-id="c5d7b-165">[SQL Server Machine Learning Services](https://docs.microsoft.com/sql/advanced-analytics/what-is-sql-server-machine-learning?view=sql-server-2017) は、ストアド プロシージャを使用して R および Python ワークロードを実行するためのデータベース内機能です。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-165">[SQL Server Machine Learning Services](https://docs.microsoft.com/sql/advanced-analytics/what-is-sql-server-machine-learning?view=sql-server-2017) are in-database capabilities for executing R and Python workloads via stored procedures.</span></span>

### <a name="nodejs-and-reactjs"></a><span data-ttu-id="c5d7b-166">Node.js と React.js</span><span class="sxs-lookup"><span data-stu-id="c5d7b-166">Node.js and React.js</span></span>

<span data-ttu-id="c5d7b-167">R スクリプトを呼び出したり、Web サイトをセキュリティで保護したりするための Web インターフェイスが作成されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-167">A web interface was created to invoke R scripts and secure the website.</span></span> <span data-ttu-id="c5d7b-168">Node.js が Web サーバー フレームワークとして選ばれた理由は、分散環境内の Web アプリケーションのための軽量で効率的なランタイム環境を実現することです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-168">Node.js was selected as the web server framework because it enables a light-weight and efficient runtime environment for web applications within a distributed environment.</span></span> <span data-ttu-id="c5d7b-169">React はユーザー インターフェイスの構築に使用され、フロントエンドに位置し、Web サーバーでホストされている Web サービスを呼び出します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-169">React is used to build user interfaces and sits on the front end and calls web services hosted on the web server.</span></span> <span data-ttu-id="c5d7b-170">Node + React は、Web サービスのプロトタイプを作成するための最速のパスをモデル パイプラインに提供すると判断されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-170">It was believed Node + React would provide the quickest path for proto-typing web services for the model pipeline.</span></span>  

## <a name="infrastructure-implementation"></a><span data-ttu-id="c5d7b-171">インフラストラクチャの実装</span><span class="sxs-lookup"><span data-stu-id="c5d7b-171">Infrastructure implementation</span></span>

<span data-ttu-id="c5d7b-172">以下のセクションでは、このプロジェクトのサーバー インフラストラクチャがどのようにデプロイされたかについて説明します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-172">The sections below describe how the server infrastructure was deployed for this project.</span></span> <span data-ttu-id="c5d7b-173">開発とデプロイのインフラストラクチャを正しく整備することは、モデリングに応用するアプローチや技法の判断と並んで、最重要の事項です。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-173">Getting the right development and deployment infrastructure can be as essential as determining the modeling approach and techniques that will be applied.</span></span>

### <a name="initial-database-load"></a><span data-ttu-id="c5d7b-174">初期データベース負荷</span><span class="sxs-lookup"><span data-stu-id="c5d7b-174">Initial Database Load</span></span>

<span data-ttu-id="c5d7b-175">最初のステップは、サブスクライバー データを巨大な .csv ファイルから Azure SQL Database にインポートすることでした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-175">The first step was to import the subscriber data from a very large .csv file into Azure SQL Database.</span></span> <span data-ttu-id="c5d7b-176">Azure SQL Database へのデータのインポートには複数のオプションがあり、この[リファレンス](https://blogs.msdn.microsoft.com/sqlcat/2010/07/30/loading-data-to-sql-azure-the-fast-way/)で説明しています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-176">There are multiple options for importing data into Azure SQL Database described in in this [reference](https://blogs.msdn.microsoft.com/sqlcat/2010/07/30/loading-data-to-sql-azure-the-fast-way/).</span></span> <span data-ttu-id="c5d7b-177">私たちが行った方法は次のとおりです:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-177">Here is how we did it:</span></span>

1. <span data-ttu-id="c5d7b-178">[こちら](https://docs.microsoft.com/azure/sql-database/sql-database-get-started-portal)の手順に従って、Azure portal からデータベースを作成しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-178">Created the database through Azure portal following steps [here](https://docs.microsoft.com/azure/sql-database/sql-database-get-started-portal).</span></span>
2. <span data-ttu-id="c5d7b-179">VM からデータベースに接続するために、[SQL Server Management Studio](https://docs.microsoft.com/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017) をダウンロードして使用しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-179">Downloaded and used [SQL Server Management Studio](https://docs.microsoft.com/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017) to connect to the database from the VM.</span></span>
3. <span data-ttu-id="c5d7b-180">[SQL インポート/エクスポート ウィザード](https://docs.microsoft.com/sql/integration-services/import-export-data/import-and-export-data-with-the-sql-server-import-and-export-wizard?view=sql-server-2017)を選択しました (時間が限られている場合、より効率的なデータ インポート オプションがあります)。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-180">Selected the [SQL Import/Export Wizard](https://docs.microsoft.com/sql/integration-services/import-export-data/import-and-export-data-with-the-sql-server-import-and-export-wizard?view=sql-server-2017) (if you are time-constrained, there are more performant data import options).</span></span> <span data-ttu-id="c5d7b-181">インポート/エクスポート ウィザードはデータ型をデータ ソースからターゲットにマップすることに注意してください。このシナリオでは、すべてのデータ要素は許容される varchar(max) データ型にマップされました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-181">Keep in mind the import/export wizard maps datatypes from the data source to the target destination; and with our scenario, all data elements were mapped to a varchar(max) data type which was acceptable.</span></span> <span data-ttu-id="c5d7b-182">異なるマッピングが必要なシナリオの場合、ウィザードでデータ型を変更できます ([参照](https://docs.microsoft.com/sql/integration-services/import-export-data/data-type-mapping-in-the-sql-server-import-and-export-wizard?view=sql-server-2017))。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-182">If your scenario requires different mappings, you can modify the datatypes in the wizard ([reference](https://docs.microsoft.com/sql/integration-services/import-export-data/data-type-mapping-in-the-sql-server-import-and-export-wizard?view=sql-server-2017)).</span></span>  
4. <span data-ttu-id="c5d7b-183">データベースに送信されるほとんどのクエリはフィールド *subscriber_id* でフィルタリングされるため、そのフィールドにインデックスを作成しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-183">Since most queries submitted to the database would filter on the field *subscriber_id*, we created an index on that field.</span></span>

### <a name="web-application"></a><span data-ttu-id="c5d7b-184">Web アプリケーション</span><span class="sxs-lookup"><span data-stu-id="c5d7b-184">Web application</span></span>

<span data-ttu-id="c5d7b-185">Web アプリケーションは 3 つの機能を担います:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-185">The web application is responsible for three functions:</span></span>

- <span data-ttu-id="c5d7b-186">認証: Web ユーザーは *React* フロントエンドを通じて *Azure Active Directory* の認証を受けます。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-186">Authentication: web users authenticate against *Azure Active Directory* through the *React* front end.</span></span>
- <span data-ttu-id="c5d7b-187">モデルのスコアリング: 特定のサブスクライバーについてユーザーから入力データを受け取り、予測応答を返す REST API を使用してサブスクライバーのデータを Web サービスに送信します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-187">Model scoring: accepts input data from the user for a specific subscriber, submits the subscriber data to the web service using the REST API, which returns a prediction response.</span></span>  
- <span data-ttu-id="c5d7b-188">モデルの再トレーニング: サブスクライバー ID を入力として受け取り、開発サーバー上の R スクリプトを呼び出してそのサブスクライバーのモデルを再トレーニングします。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-188">Model re-training: accepts a subscriber identifier as input an,d invokes an R script on the development server to re-train the model for that subscriber.</span></span>

<span data-ttu-id="c5d7b-189">*Azure Active Directory* によるシングル サインオン (SSO) の実装は予想以上に困難であると判明しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-189">Implementing single sign-on (SSO) with *Azure Active Directory* turned out to be more of a challenge than expected.</span></span> <span data-ttu-id="c5d7b-190">これは、シングル ページ アプリケーション (SPA) のフレームワークによるものでした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-190">This was due to the single page application (SPA) framework.</span></span> <span data-ttu-id="c5d7b-191">ある特定の Azure Active Directory ライブラリが成功の鍵でした: [react-adal](https://github.com/salvoravida/react-adal)。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-191">One specific Azure Active Directory library was key for success: [react-adal](https://github.com/salvoravida/react-adal).</span></span> <span data-ttu-id="c5d7b-192">以下のリファレンスで、認証の実装に役立つガイダンスが提供されていました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-192">The following references provided helpful guidance for implementing authentication:</span></span>

- [<span data-ttu-id="c5d7b-193">Azure AD の認証シナリオ</span><span class="sxs-lookup"><span data-stu-id="c5d7b-193">Authentication Scenarios for Azure AD</span></span>](https://docs.microsoft.com/azure/active-directory/develop/active-directory-authentication-scenarios)
- [<span data-ttu-id="c5d7b-194">シングル ページ アプリケーション</span><span class="sxs-lookup"><span data-stu-id="c5d7b-194">Single Page Application</span></span>](https://docs.microsoft.com/azure/active-directory/develop/active-directory-authentication-scenarios#single-page-application-spa)

### <a name="development-vm-mls-930"></a><span data-ttu-id="c5d7b-195">開発 VM (MLS 9.3.0)</span><span class="sxs-lookup"><span data-stu-id="c5d7b-195">Development VM (MLS 9.3.0)</span></span>

<span data-ttu-id="c5d7b-196">開発 VM はモデルの開発、トレーニングと再トレーニング、および分類モデルのデプロイをホストしました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-196">The development VM hosted model development, training and re-training, and deployment of the classification model.</span></span> <span data-ttu-id="c5d7b-197">Azure VM (DS 13 V2) に Linux/Ubuntu 16.10 がプロビジョニングされ、z次のものがベース VM にインストールされました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-197">An Azure VM (DS13 V2) was provisioned with Linux/Ubuntu 16.10 and the following were installed to the base VM:</span></span>

- <span data-ttu-id="c5d7b-198">Machine Learning Server 9.3.0 の使用方法については、[こちら](https://docs.microsoft.com/machine-learning-server/install/machine-learning-server-install)を参照してください。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-198">Machine Learning Server 9.3.0 using instructions available [here](https://docs.microsoft.com/machine-learning-server/install/machine-learning-server-install).</span></span> <span data-ttu-id="c5d7b-199">必ず、セットアップ検証の手順を実行してインストールを確認してください。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-199">Be sure to run through the setup verification steps to confirm the installation.</span></span> <span data-ttu-id="c5d7b-200">これは開発 VM であったため、*Web サービスのデプロイとリモート接続の有効化*に関するセクションは無視しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-200">Because this was the development VM, the section ‘*Enable web service deployment and remote connections*’ was disregarded.</span></span>
- <span data-ttu-id="c5d7b-201">[RStudio Server](https://www.rstudio.com/products/rstudio/download-server/) (オープン ソースのバージョン)。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-201">[RStudio Server](https://www.rstudio.com/products/rstudio/download-server/) (Open Source Version).</span></span> <span data-ttu-id="c5d7b-202">R/r ベースを再インストールしないよう注意してください (以前に MLS 9.3.0 でインストール済み)。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-202">Be careful not to re-install R/r-base (it was installed previously with MLS 9.3.0).</span></span>  
- <span data-ttu-id="c5d7b-203">VM に[ネットワーク セキュリティ グループを追加](https://docs.microsoft.com/azure/virtual-machines/windows/nsg-quickstart-portal)して、RStudio Server 用のポート 8787 でインバウンド接続を許可します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-203">[Add a network security group](https://docs.microsoft.com/azure/virtual-machines/windows/nsg-quickstart-portal) to the VM to allow for inbound connections over port 8787 for RStudio Server.</span></span>  
- <span data-ttu-id="c5d7b-204">開発 VM と Azure SQL Database 間の通信を処理するための ODBC ドライバー。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-204">ODBC drivers to handle the communication between the development VM and Azure SQL Database.</span></span> <span data-ttu-id="c5d7b-205">次の ODBC ドライバーが VM にインストールされました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-205">The following odbc drivers were installed on the VM:</span></span>  
- <span data-ttu-id="c5d7b-206">Linux/ubuntu 16.10 と互換性のある [SQL Server 17 用 ODBC ドライバー](https://www.microsoft.com/download/details.aspx?id=56567)</span><span class="sxs-lookup"><span data-stu-id="c5d7b-206">The [ODBC Driver for SQL Server 17](https://www.microsoft.com/download/details.aspx?id=56567) compatible with Linux/ubuntu 16.10</span></span>  
- <span data-ttu-id="c5d7b-207">[ODBC を使用したリレーショナル データのインポート](https://docs.microsoft.com/machine-learning-server/r/how-to-revoscaler-data-odbc)に関する記事でインストールが指示されているオープン ソースの ODBC ドライバー unixodbc。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-207">An open source ODBC driver unixodbc with installation instructions from [Import relational data using ODBC](https://docs.microsoft.com/machine-learning-server/r/how-to-revoscaler-data-odbc).</span></span> <span data-ttu-id="c5d7b-208">注: この記事の Ubuntu 関連の手順には 2 か所の誤りがあります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-208">Note: this article has two typos for Ubuntu instructions.</span></span>  
- <span data-ttu-id="c5d7b-209">unixodbc がインストールされているかどうかを確認するには:       ````Apt list –installed | grep unixODBC (should be unixodbc)````</span><span class="sxs-lookup"><span data-stu-id="c5d7b-209">To check if unixodbc is installed:       ````Apt list –installed | grep unixODBC (should be unixodbc)````</span></span>
      - <span data-ttu-id="c5d7b-210">ドライバーをインストールするには: ````sudo apt-get install unixodbc-devel unixodbc-bin unixodbc (should be unixodbc-dev)````</span><span class="sxs-lookup"><span data-stu-id="c5d7b-210">And to install the driver: ````sudo apt-get install unixodbc-devel unixodbc-bin unixodbc (should be unixodbc-dev)````</span></span>

### <a name="operations-vm-mls-930"></a><span data-ttu-id="c5d7b-211">運用 VM (MLS 9.3.0)</span><span class="sxs-lookup"><span data-stu-id="c5d7b-211">Operations VM (MLS 9.3.0)</span></span>

<span data-ttu-id="c5d7b-212">運用 VM はモデルの Web サービスとエンドポイントをホストし、Swagger ファイルを格納し、分類モデルのシリアライズされたバージョンを格納しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-212">The operations VM hosted the model web services and endpoints, stored the Swagger files, and stored serialized versions of the classification models.</span></span> <span data-ttu-id="c5d7b-213">構成は MLS 開発サーバーによく似ています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-213">Configuration is very similar to the MLS development server.</span></span> <span data-ttu-id="c5d7b-214">ただし、運用化のために構成されています。つまり、REST エンドポイントのサービスを提供するために必要な Web サービスがインストールされています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-214">However, it is configured for operationalization which means the web services necessary to serve the REST endpoints are installed.</span></span> <span data-ttu-id="c5d7b-215">運用 VM をデプロイするために、デプロイを迅速化する ARM テンプレートがあります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-215">To deploy the operations VM, there are ARM templates that make deployment quick.</span></span> <span data-ttu-id="c5d7b-216">参照:[ARM テンプレートを使用した分析を運用化するための Microsoft Machine Learning Server 9.3 の構成](https://blogs.msdn.microsoft.com/mlserver/2018/02/27/configuring-microsoft-machine-learning-server-9-3-to-operationalize-analytics-using-arm-templates/)。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-216">See: [Configuring Microsoft Machine Learning Server 9.3 to Operationalize Analytics using ARM Templates](https://blogs.msdn.microsoft.com/mlserver/2018/02/27/configuring-microsoft-machine-learning-server-9-3-to-operationalize-analytics-using-arm-templates/).</span></span> <span data-ttu-id="c5d7b-217">このプロジェクトでは、この [ARM テンプレート](https://github.com/Microsoft/microsoft-r/tree/master/mlserver-arm-templates/one-box-configuration/linux)を使用して *One-Box* 構成をデプロイしました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-217">For our project, a *One-Box* configuration was deployed using this [ARM template](https://github.com/Microsoft/microsoft-r/tree/master/mlserver-arm-templates/one-box-configuration/linux).</span></span>  
<span data-ttu-id="c5d7b-218">これにより、モデル パイプラインをサポートするためのサーバー コンポーネントを準備して稼働させました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-218">With this, the server components to support the model pipeline were up and running.</span></span>

## <a name="model-implementation"></a><span data-ttu-id="c5d7b-219">モデルの実装</span><span class="sxs-lookup"><span data-stu-id="c5d7b-219">Model implementation</span></span>

<span data-ttu-id="c5d7b-220">1 つの重要な決定がこのプロジェクトの最終的なモデル設計に影響を及ぼし、単一のモノリシック モデルではなく "多モデル" 設計に移行することになりました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-220">One key decision influenced the final model design for this project and that was to move to a “many model” design rather than a single, monolithic model.</span></span> <span data-ttu-id="c5d7b-221">違い: 個々のサブスクライバーは、すべてのサブスクライバーにサービスを提供する 1 つの大きな分類モデルではなく、独自の分類モデルを持ちます。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-221">The difference: each subscriber has their own classification model rather than one big classification model to serve all subscribers.</span></span> <span data-ttu-id="c5d7b-222">モデルが小規模なほどメモリ占有領域が小さくなり、運用環境で水平方向のスケーリングが容易であったため、この顧客にとっては好ましいアプローチでした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-222">For this customer, the approach was preferred because a smaller model had a smaller memory footprint and was easier to scale horizontally in production.</span></span>

### <a name="data-import"></a><span data-ttu-id="c5d7b-223">データのインポート</span><span class="sxs-lookup"><span data-stu-id="c5d7b-223">Data import</span></span>

<span data-ttu-id="c5d7b-224">モデル開発に必要なすべてのデータは *Azure SQL Database* にあります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-224">All the data needed for model development resided in an *Azure SQL Database*.</span></span> <span data-ttu-id="c5d7b-225">モデルのトレーニングと再トレーニングのために、2 段階でデータのインポートが行われました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-225">For model training and retraining, data import was done in two stages:</span></span>

1. <span data-ttu-id="c5d7b-226">特定の *subscriber_id* と返される結果セットのデータを取得するために、クエリがデータベースに送信されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-226">A query was submitted to the database to retrieve data for a specific *subscriber_id* and a result set returned.</span></span> <span data-ttu-id="c5d7b-227">データベースへのクエリ アクセスのために、2 つのオプションが検討されました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-227">Two options were considered for query access to the database:</span></span>

- <span data-ttu-id="c5d7b-228">[RxSQLServerData](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/rxsqlserverdata) という RevoScaleR 関数</span><span class="sxs-lookup"><span data-stu-id="c5d7b-228">A RevoScaleR function called [RxSQLServerData](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/rxsqlserverdata)</span></span>
- <span data-ttu-id="c5d7b-229">R odbc パッケージ</span><span class="sxs-lookup"><span data-stu-id="c5d7b-229">The R odbc package</span></span>

<span data-ttu-id="c5d7b-230">データベース レベルでのデータ フィルタリングを可能にする R "odbc" ライブラリを使用することに決定しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-230">It was decided to use the R “odbc” library which enabled data filtering at the database level.</span></span> <span data-ttu-id="c5d7b-231">特定のサブスクライバー モデルに必要な行のみにデータベース テーブルをフィルタリングすることで、R に読み込んで処理する行数を最小化しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-231">Filtering the database table for only the rows needed for a specific subscriber model minimized the number of rows to be read into R and processed.</span></span> <span data-ttu-id="c5d7b-232">それにより、各モデルをトレーニングまたは再トレーニングするために必要なメモリ、計算量、および全体的な時間が短縮されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-232">That reduced the memory, compute, and overall time needed to train or retrain each model.</span></span>  

1. <span data-ttu-id="c5d7b-233">結果セットは R データ フレームに変換され、分類アルゴリズムの要件に従って一部のデータ型は varchar から整数または数値に明示的に変換されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-233">The result set was converted into an R data frame and some of the data types were explicitly converted from varchars to integers or numerics as required by the classification algorithms.</span></span> <span data-ttu-id="c5d7b-234">この機能のために、RevoScaleR 関数 [rxImport](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/rximport) が使用されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-234">For this functionality, the RevoScaleR function [rxImport](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/rximport) was used.</span></span> <span data-ttu-id="c5d7b-235">*rxImport* 関数は RevoScaleR と MicrosoftML にバンドルされており、マルチスレッドの設計になっています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-235">The *rxImport* function is bundled with RevoScaleR and MicrosoftML and is engineered to be multi-threaded.</span></span> <span data-ttu-id="c5d7b-236">ここでは、どのようにそれを使用したかの例を示します:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-236">Here is an example of how we used it:</span></span>

````r

# Populate the data frame and modify column types as needed
input_data <- rxImport(sqlServerDataDS, colClasses = c(  
Approved="integer",
      OnTimeArrivalRate="numeric",
      Amount="numeric",
      IsInformed="numeric",
      <continue with list of columns> )
# View the characteristics of the variables in the data source
rxGetInfo (input_data, getVarInfo = TRUE)
````

## <a name="unbalanced-data"></a><span data-ttu-id="c5d7b-237">不均衡なデータ</span><span class="sxs-lookup"><span data-stu-id="c5d7b-237">Unbalanced data</span></span>

<span data-ttu-id="c5d7b-238">レコメンデーション モデルの目標は、顧客が契約を更新する確率を予測し、その確率を "はい"、"いいえ"、または "可能性あり" に分類することであったため、分類アルゴリズムが使用されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-238">Because the goal of the recommendation model was to forecast the probability a customer would renew a contract and categorize the probability it into a ‘yes’, ‘no’, or ‘maybe’, a classification algorithm was used.</span></span> <span data-ttu-id="c5d7b-239">分類アルゴリズムの精度とパフォーマンスに大きく影響する可能性がある 1 つの問題は、不均衡なデータ セットです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-239">One problem that can seriously impact the accuracy and performance of a classification algorithm is an unbalanced data set.</span></span>  
<span data-ttu-id="c5d7b-240">ある "クラス" に対して別の "クラス" よりも多くのサンプルが存在する場合、データ セットは不均衡です。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-240">A data set is unbalanced if there are many more samples for one ‘class’ than another ‘class’.</span></span> <span data-ttu-id="c5d7b-241">この場合、各サブスクライバーの利用可能な行数のバランスが不均衡でした。1 人のサブスクライバーにつき 100 万行を超える場合もあれば、330 人の顧客のデータが 100 行未満の場合もありました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-241">In this case, the number of rows available for each subscriber was unbalanced: on the high end, one subscriber had 1 million+ rows; on the low end, 330 customers had less than 100 rows of data.</span></span> <span data-ttu-id="c5d7b-242">次のグラフは、サブスクライバーあたりの行数 (サンプル) の不均衡を示しています: ![imbalance-chart](assets/recommendation-engine-optimization/recommendaton_engine_chart.png)</span><span class="sxs-lookup"><span data-stu-id="c5d7b-242">The graph below shows the imbalance with the number of rows (samples) per subscriber: ![imbalance-chart](assets/recommendation-engine-optimization/recommendaton_engine_chart.png)</span></span>

<span data-ttu-id="c5d7b-243">不均衡なデータ セットを取り扱うための 1 つの技法は、データ セットを変更し、情報不足のクラスをオーバーサンプリングするか、情報過多のクラスをアンダーサンプリングするというものです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-243">One technique for treating an unbalanced data set is to change the data set and either over-sample the under-represented class, or under-sample the over-represented class.</span></span> <span data-ttu-id="c5d7b-244">もう 1 つの技法は、データに関するデータ所有者の正確な知識とその属性を使用して、追加のデータを合成的に生成するというものです。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-244">Another technique is to synthetically generate additional data using the data owner’s exact knowledge of the data and its attributes.</span></span> <span data-ttu-id="c5d7b-245">顧客はサブスクライバーの最小サンプル サイズのしきい値を確立しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-245">The customer established a threshold for the minimum sample size for a subscriber.</span></span> <span data-ttu-id="c5d7b-246">そのしきい値を下回るサブスクライバーについては、データを扱う必要があります。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-246">For subscribers below that threshold, data would need to be treated.</span></span> <span data-ttu-id="c5d7b-247">このプロジェクトでは、両方のアプローチが検討されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-247">For this project both approaches were explored.</span></span>

## <a name="algorithm-selection"></a><span data-ttu-id="c5d7b-248">アルゴリズムの選択</span><span class="sxs-lookup"><span data-stu-id="c5d7b-248">Algorithm Selection</span></span>

<span data-ttu-id="c5d7b-249">*rxDForest*、*rxFastTrees*、および *rxFastForest* という 3 種類の分類アルゴリズムの実装が評価されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-249">Three different classification algorithm implementations were evaluated: *rxDForest*, *rxFastTrees*, and *rxFastForest*.</span></span> <span data-ttu-id="c5d7b-250">3 つのアルゴリズムはすべてマルチスレッドと並列処理を利用します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-250">All three algorithms take advantage of multi-threading and parallelism.</span></span> <span data-ttu-id="c5d7b-251">また Microsoft ML は、利用可能であれば複数の CPU または GPU を使用します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-251">And Microsoft ML will use multiple CPUs or GPUs if available.</span></span> <span data-ttu-id="c5d7b-252">モデルを評価するための基準には、次のものがあります:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-252">The criteria for evaluating the models included:</span></span>

- <span data-ttu-id="c5d7b-253">新しいモデルは元のモデルよりも正確だったか?</span><span class="sxs-lookup"><span data-stu-id="c5d7b-253">Were the new models more accurate that the original model?</span></span>
- <span data-ttu-id="c5d7b-254">運用環境で稼働しているモデルのメモリ占有領域はどれくらいだったか?</span><span class="sxs-lookup"><span data-stu-id="c5d7b-254">What was the memory footprint of the models running in production?</span></span> <span data-ttu-id="c5d7b-255">運用環境は、精度に妥協することなく、ほぼリアルタイムの予測応答を伴って多数のモデルの同時実行をサポートできたか?</span><span class="sxs-lookup"><span data-stu-id="c5d7b-255">Without compromising accuracy, could the operational environment support simultaneous execution of many models with near real-time prediction response?</span></span>
- <span data-ttu-id="c5d7b-256">アルゴリズムは不均衡なデータ セットをどれくらいうまく扱えたか?</span><span class="sxs-lookup"><span data-stu-id="c5d7b-256">How well did the algorithm handle the unbalanced data set?</span></span> <span data-ttu-id="c5d7b-257">合成データを生成することによって不均衡を事前処理する必要があったか?</span><span class="sxs-lookup"><span data-stu-id="c5d7b-257">Would the imbalance need to be pre-treated by generating synthetic data?</span></span>

<span data-ttu-id="c5d7b-258">次の表は、結果をまとめたものです:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-258">The table below summarizes the findings:</span></span>

| <span data-ttu-id="c5d7b-259">アルゴリズム</span><span class="sxs-lookup"><span data-stu-id="c5d7b-259">Algorithm</span></span> | <span data-ttu-id="c5d7b-260">説明</span><span class="sxs-lookup"><span data-stu-id="c5d7b-260">Description</span></span> | <span data-ttu-id="c5d7b-261">結果</span><span class="sxs-lookup"><span data-stu-id="c5d7b-261">Findings</span></span> | <span data-ttu-id="c5d7b-262">メモ</span><span class="sxs-lookup"><span data-stu-id="c5d7b-262">Notes</span></span> |
| :--------- | :------------ | :--------- | :--------------- |
| [<span data-ttu-id="c5d7b-263">rxFastTrees</span><span class="sxs-lookup"><span data-stu-id="c5d7b-263">rxFastTrees</span></span>](https://docs.microsoft.com/machine-learning-server/r-reference/microsoftml/rxfasttrees) | <span data-ttu-id="c5d7b-264">FastRank のマルチスレッド バージョンを実装するブースト デシジョン ツリーの並列実装。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-264">Parallel implementation of boosted decision tree that implements multi-threaded version of FastRank.</span></span> | <span data-ttu-id="c5d7b-265">正確、最速のパフォーマンス。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-265">Accurate, fastest performance.</span></span> | <span data-ttu-id="c5d7b-266">不均衡なデータのための特別な機能はなし。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-266">No special features for unbalanced data.</span></span> <span data-ttu-id="c5d7b-267">事前処理されたデータを入力として提供する必要があった</span><span class="sxs-lookup"><span data-stu-id="c5d7b-267">Pre-treated data needed to be provided as input</span></span> |
| [<span data-ttu-id="c5d7b-268">rxFastForest</span><span class="sxs-lookup"><span data-stu-id="c5d7b-268">rxFastForest</span></span>](https://docs.microsoft.com/machine-learning-server/r-reference/microsoftml/rxfastforest) | <span data-ttu-id="c5d7b-269">ランダム フォレストの並列実装。rxFastTrees を使用してデシジョン ツリーのアンサンブル学習器を構築する。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-269">Parallel implementation of random forest and uses rxFastTrees to build an ensemble learner of decision trees.</span></span> | <span data-ttu-id="c5d7b-270">事前処理されたデータによってオリジナルより精度が向上。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-270">Better accuracy than original with pre-treated data.</span></span> <span data-ttu-id="c5d7b-271">rxDForest よりメモリ使用量が少なく、高速</span><span class="sxs-lookup"><span data-stu-id="c5d7b-271">Less memory intensive, faster than rxDForest</span></span> |<span data-ttu-id="c5d7b-272">不均衡なデータのための特別な機能はなし。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-272">No special features for unbalanced data.</span></span> <span data-ttu-id="c5d7b-273">事前処理されたデータを入力として提供。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-273">Pre-treated data provided as input.</span></span> |
| [<span data-ttu-id="c5d7b-274">rxDForest</span><span class="sxs-lookup"><span data-stu-id="c5d7b-274">rxDForest</span></span>](https://docs.microsoft.com/machine-learning-server/r-reference/revoscaler/rxdforest) | <span data-ttu-id="c5d7b-275">ランダム フォレストの並列実装。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-275">Parallel implementation of random forest.</span></span> <span data-ttu-id="c5d7b-276">RevoScaleR に含まれている。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-276">Included in RevoScaleR.</span></span> <span data-ttu-id="c5d7b-277">不均衡なデータの処理 (欠落しているデータの除去、データの条件付け、サンプルの階層化の処理) をすべて関数呼び出し内で実行できる。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-277">Can deal with unbalanced data (removes missing data, conditions data, handles stratification of samples) all within the function call.</span></span> | <span data-ttu-id="c5d7b-278">元のモデルよりも高速。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-278">Faster than original model.</span></span> <span data-ttu-id="c5d7b-279">元のモデルと同等以上の精度。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-279">Same or better accuracy than original model.</span></span> <span data-ttu-id="c5d7b-280">再サンプリングと合成のためのさまざまな技法を使用して不均衡なデータ セットを処理する。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-280">Handles unbalanced data set using a variety of techniques for re-sampling and synthesizing.</span></span> <span data-ttu-id="c5d7b-281">最大のメモリ占有領域。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-281">Largest memory footprint.</span></span>  | <span data-ttu-id="c5d7b-282">条件付けされたデータが関数内部に含まれるため、メモリ占有領域が最大。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-282">Largest memory footprint because it includes the conditioned data within the function.</span></span>   <span data-ttu-id="c5d7b-283">データの処理は良好でしたが、データ所有者が提供するカスタマイズされた変換ほど良好ではありませんでした。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-283">Treatment of the data was good but not as good as the customized transformations provided by the data owner.</span></span> |

<span data-ttu-id="c5d7b-284">最終的に、顧客は *rxFastForest* アルゴリズムを選択しました。また、不均衡なデータの取り扱いについては、[vtreat](https://cran.r-project.org/web/packages/vtreat/index.html) ライブラリを使用し、カスタマイズされたデータの事前処理ステップを追加することによって、情報不足のサブスクライバーのデータを合成的に生成することに決定しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-284">In the end, the customer selected the *rxFastForest* algorithm and decided to treat the unbalanced data by using the [vtreat](https://cran.r-project.org/web/packages/vtreat/index.html) library and adding a customized data pre-processing step to synthetically generate data for the under-represented subscribers.</span></span>

## <a name="model-deployment--web-services"></a><span data-ttu-id="c5d7b-285">モデル デプロイと Web サービス</span><span class="sxs-lookup"><span data-stu-id="c5d7b-285">Model Deployment & Web Services</span></span>

<span data-ttu-id="c5d7b-286">デプロイ用のモデルを運用 VM に公開することは簡単であり、[mrsdeploy を使用して R モデルを Web サービスとしてデプロイする方法](https://docs.microsoft.com/machine-learning-server/operationalize/quickstart-publish-r-web-service)に関するこちらのクイック スタート ドキュメントで説明されています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-286">Publishing a model for deployment to the operations VM is straight-forward and documented in this QuickStart documentation [Deploy an R Model as a web service with mrsdeploy](https://docs.microsoft.com/machine-learning-server/operationalize/quickstart-publish-r-web-service).</span></span>
<span data-ttu-id="c5d7b-287">このシナリオでは、開発 VM でモデルを作成した後、次の手順を使用して運用 VM に公開しました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-287">In our scenario, once the models were created on the development VM, they were published on the operations VM using these steps:</span></span>

1. <span data-ttu-id="c5d7b-288">mrsdeploy パッケージで認証に使用できる 2 つの関数のいずれかを使用して、開発者 VM から運用 VM へのリモート ログインを確立します。remoteLogin() ではローカル管理者名とパスワードを使用し、remoteLoginAAD() では Azure Active Directory を使用します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-288">Establish a remote login from the developer VM to the operations VM using one of two functions available in the mrsdeploy package for authentication; remoteLogin() using a local admin name and password, or remoteLoginAAD() using Azure Active Directory.</span></span> <span data-ttu-id="c5d7b-289">どちらのオプションについても、mrsdeploy を使用して Machine Learning Server または R Server にログインしリモート セッションを開く方法に関するこちらのリファレンスで説明されています。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-289">Both options are described in this reference Log in to Machine Learning Server or R Server with mrsdeploy and open a remote session.</span></span>  
2. <span data-ttu-id="c5d7b-290">モデルがトレーニングされたら、mrsdeploy パッケージの publishService または updateService 関数を使用して、運用 VM に公開します。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-290">Once a model is trained, publish it to the operations VM using the publishService or updateService functions in the mrsdeploy package.</span></span> <span data-ttu-id="c5d7b-291">このプロジェクトでは複数のデプロイ方法を使用し、方法に応じて新しいモデルを公開または既存のモデルを更新しました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-291">For this project, we used multiple deployment approaches, and—depending on the approach—either a new model was published, or an existing model was updated.</span></span> <span data-ttu-id="c5d7b-292">両方のケースを扱うために、次のコードが実装されました:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-292">The following code was implemented to handle both cases:</span></span>

````r
# If the service does not exist, publish it and if it does exist, update it.  
# No service by this name so publish one
 api <- publishService(serviceName, code =sc_predict, model = model,  
      inputs = list(prop_data="data.frame"),  
      outputs = list(answer = "numeric"), v = "v1.0.0" )
 print("=========== Model Created =============")
} else {
# A service by this name already exists, update it  
 api <- updateService(serviceName, model = model,
     inputs = list(prop_data="data.frame"), v = "v1.0.0" )
 print("=========== Model Updated =============")
}
 ````

デプロイされると、モデルはシリアライズされて運用サーバーに格納され、*標準*または*リアルタイム*のどちらかのモードで Web サービス経由で使用できます。 Web サービスが標準モードで呼び出されるたびに、R と必要なライブラリが呼び出しごとに読み込まれ、アンロードされます。 対照的に、*リアルタイム* モードでは、R とライブラリは一度しか読み込まれず、後続の Web サービス呼び出しで再利用されます。 Web サービス呼び出しのオーバーヘッドの大半は R とライブラリの読み込みであるため、リアルタイム モードではモデル スコアリングの待ち時間が大幅に短縮され、応答時間は 10 ミリ秒を切る可能性があります。 標準とリアルタイムの各オプションのドキュメントおよび参考例については、[こちら](https://docs.microsoft.com/machine-learning-server/operationalize/concept-what-are-web-services)を参照してください。 リアルタイムは単一の予測に適していますが、スコアリングのために入力データ フレームを渡すこともできます。 <span data-ttu-id="c5d7b-299">これについては、このリファレンスに説明があります。「[mrsdeploy を使用したバッチ処理による非同期 Web サービスの使用](https://docs.microsoft.com/machine-learning-server/operationalize/how-to-consume-web-service-asynchronously-batch)」。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-299">That is described in this reference: [Asynchronous web service consumption via batch processing with mrsdeploy](https://docs.microsoft.com/machine-learning-server/operationalize/how-to-consume-web-service-asynchronously-batch).</span></span>

## <a name="conclusion"></a><span data-ttu-id="c5d7b-300">まとめ</span><span class="sxs-lookup"><span data-stu-id="c5d7b-300">Conclusion</span></span>

<span data-ttu-id="c5d7b-301">Microsoft Machine Learning Server に組み込まれている MicrosoftML および RevoScaleR ライブラリの並列性を利用することで、数百人規模のサブスクライバー向けの個別分類モデルの開発、デプロイ、スコアリングが高速化されました。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-301">Leveraging the parallelism of the MicrosoftML and RevoScaleR libraries built into Microsoft Machine Learning Server accelerated development, deployment, and scoring of individual classification models for hundreds of subscribers.</span></span> <span data-ttu-id="c5d7b-302">モデルの精度が向上し、トレーニングと再トレーニングの時間が短縮されましたが、既存の R コード ベースへの変更は最小限で済みます。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-302">Model accuracy improved, and training and re-training times were compressed—all with minimal changes to the existing R code base.</span></span>
<span data-ttu-id="c5d7b-303">モデル パイプラインをサポートするためのインフラストラクチャの実装と、テクノロジ コンポーネントを正しく隅々まで構成することは複雑な作業かもしれません。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-303">Implementing the infrastructure to support a model pipeline and getting the technology components configured correctly end-to-end can be complex.</span></span> <span data-ttu-id="c5d7b-304">独自のアプローチで作業を始めるためのリファレンスをいくつか紹介します:</span><span class="sxs-lookup"><span data-stu-id="c5d7b-304">Here are some references to get your started with your own approach:</span></span>

- [<span data-ttu-id="c5d7b-305">Machine Learning Server のドキュメント</span><span class="sxs-lookup"><span data-stu-id="c5d7b-305">Machine Learning Server Documentation</span></span>](https://docs.microsoft.com/machine-learning-server/)
- [<span data-ttu-id="c5d7b-306">Machine Learning Server の R チュートリアル</span><span class="sxs-lookup"><span data-stu-id="c5d7b-306">R Tutorials for Machine Learning Server</span></span>](https://docs.microsoft.com/advanced-analytics/tutorials/sql-server-r-tutorials?view=sql-server-2017)
- [<span data-ttu-id="c5d7b-307">Machine Learning Server の R サンプル</span><span class="sxs-lookup"><span data-stu-id="c5d7b-307">R Samples for Machine Learning Server</span></span>](https://docs.microsoft.com/machine-learning-server/r/r-samples)
- [<span data-ttu-id="c5d7b-308">R 関数ライブラリ リファレンス</span><span class="sxs-lookup"><span data-stu-id="c5d7b-308">R Function Library Reference</span></span>](https://docs.microsoft.com/machine-learning-server/r-reference/introducing-r-server-r-package-reference)

## <a name="references"></a><span data-ttu-id="c5d7b-309">参照</span><span class="sxs-lookup"><span data-stu-id="c5d7b-309">References</span></span>

<span data-ttu-id="c5d7b-310">小売業向けのその他の予測ソリューションの構築に興味がある場合は、Azure [AI ギャラリー](https://gallery.azure.ai/)の[小売業セクション](https://gallery.azure.ai/industries/retail)を参照してください。</span><span class="sxs-lookup"><span data-stu-id="c5d7b-310">If you are interested in building other predictive solutions for your retail business, visit the [retail section](https://gallery.azure.ai/industries/retail) of the Azure [AI Gallery](https://gallery.azure.ai/).</span></span>  