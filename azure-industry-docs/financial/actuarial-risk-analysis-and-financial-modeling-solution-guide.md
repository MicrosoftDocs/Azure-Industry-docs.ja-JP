---
title: 保険数理リスク分析を Azure に移行するためのガイド
author: scseely
ms.author: scseely
ms.date: 11/20/2019
ms.topic: article
ms.service: industry
description: 保険数理開発者が既存のソリューションとサポート インフラストラクチャを Azure に移行する方法。
ms.openlocfilehash: 456c054cf3a6165f160005ba8ea2c155637faa07
ms.sourcegitcommit: f030566b177715794d2ad857b150317e72d04d64
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/20/2019
ms.locfileid: "74234534"
---
# <a name="actuarial-risk-analysis-and-financial-modeling-solution-guide"></a><span data-ttu-id="f8c8e-103">保険数理リスク分析と金融モデリングのソリューション ガイド</span><span class="sxs-lookup"><span data-stu-id="f8c8e-103">Actuarial risk analysis and financial modeling solution guide</span></span>

<span data-ttu-id="f8c8e-104">ここ数年にわたり、保険関連商品を提供する保険業者および会社では、いくつかの新しい規制が施行されていることを認識しています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-104">Over the last several years, insurers and companies that provide insurance-like products have seen several new regulations come into place.</span></span> <span data-ttu-id="f8c8e-105">これらの新しい規制では、保険業者のより広範な金融モデリングが求められます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-105">These new regulations have required more extensive financial modeling for insurers.</span></span> <span data-ttu-id="f8c8e-106">欧州連合で制定された[ソルベンシー II](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) では、保険業者は年末における支払能力を確認するために適切な分析を行ったことを示すよう求められます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-106">The European Union enacted [Solvency II](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) which requires insurers to demonstrate that they have done proper analysis to validate that the insurer will be solvent at the end of the year.</span></span> <span data-ttu-id="f8c8e-107">変額年金を提供する保険業者は、資産および負債キャッシュ フローの広範な分析に関する[保険数理ガイドライン XLIII](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) に従う必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-107">Insurers who provide variable annuities have to follow [Actuarial Guideline XLIII](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) with extensive analysis of asset and liability cash flows.</span></span> <span data-ttu-id="f8c8e-108">保険関連商品を配布する業者を含め、すべての種類の保険業者は、2021 年までに[国際財務報告基準 17](https://www.ifrs.org/supporting-implementation/supporting-materials-by-ifrs-standard/ifrs-17/) (IFRS 17) を実装する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-108">All types of insurers, including those who distribute insurance like products, will have to implement [International Financial Reporting Standard 17](https://www.ifrs.org/supporting-implementation/supporting-materials-by-ifrs-standard/ifrs-17/) (IFRS 17) by 2021.</span></span> <span data-ttu-id="f8c8e-109">保険業者が担当する管轄に応じて、その他の規制が存在します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-109">Other regulations exist depending on the jurisdictions the insurers operate in.</span></span> <span data-ttu-id="f8c8e-110">これらの標準や規制では、保険数理士は資産および負債のモデリング時にコンピューティング集中型手法を使用することが求められます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-110">These standards and regulations require actuaries to use compute-intensive techniques when modeling assets and liabilities.</span></span> <span data-ttu-id="f8c8e-111">ほとんどの分析で、資産および負債などの連続入力について確率的に生成されたシナリオ データが利用されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-111">Much of the analysis will make use of stochastically generated scenario data over seriatim inputs of things like assets and liabilities.</span></span> <span data-ttu-id="f8c8e-112">保険数理士は、規制で求められるものよりはるかに多くの金融モデリングと計算を行い、規制レポートを生成するモデルの入力テーブルを作成します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-112">Beyond regulatory needs, actuaries do a fair amount of financial modeling and computation to generate the input tables for the models that generate the regulatory reports.</span></span> <span data-ttu-id="f8c8e-113">内部グリッドではコンピューティング ニーズが満たされないため、保険数理士は徐々にクラウドに移行しています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-113">Internal grids do not satisfy the computational needs, so actuaries are steadily moving to the cloud.</span></span>

<span data-ttu-id="f8c8e-114">保険数理士はクラウドに移行することで、結果の確認、評価、検証のためにより多くの時間を確保することができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-114">Actuaries move to the cloud to get more time to review, evaluate, and validate results.</span></span> <span data-ttu-id="f8c8e-115">規制機関によって保険業者の監査が行われる際に、保険数理士はその結果を説明できる必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-115">When regulators audit insurers, the actuaries need to be able to explain their results.</span></span> <span data-ttu-id="f8c8e-116">クラウドに移行することで、並列処理を利用して 24 時間から 120 時間 (クロック時間) で 20,000 時間の分析を行うためのコンピューティング リソースにアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-116">The move to the cloud gives access to the computing resources to run 20000 hours of analysis in 24-120 hours of clock time through the power of parallelization.</span></span> <span data-ttu-id="f8c8e-117">このようなスケールのニーズを満たせるように、保険数理ソフトウェアを作成する企業の多くでは、Azure で計算を行うことができるソリューションが提供されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-117">To assist with this need for scale, many of the companies that create actuarial software provide solutions that allow calculations to run in Azure.</span></span> <span data-ttu-id="f8c8e-118">これらのソリューションの一部は、[HPC Pack](https://docs.microsoft.com/powershell/high-performance-computing/overview?view=hpc16-ps&WT.mc_id=riskmodel-docs-scseely) などの Azure およびオンプレミスで実行されるテクノロジに基づきます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-118">Some of these solutions are built on technologies that run on premises and Azure like [HPC Pack](https://docs.microsoft.com/powershell/high-performance-computing/overview?view=hpc16-ps&WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-119">その他は Azure のネイティブのものであり、[Azure Batch](https://docs.microsoft.com/azure/batch?WT.mc_id=riskmodel-docs-scseely)、[Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets?WT.mc_id=riskmodel-docs-scseely)、あるいはカスタム スケーリング ソリューションが使用されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-119">Others are Azure native and use [Azure Batch](https://docs.microsoft.com/azure/batch?WT.mc_id=riskmodel-docs-scseely), [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets?WT.mc_id=riskmodel-docs-scseely), or a custom scaling solution.</span></span>

<span data-ttu-id="f8c8e-120">この記事では、保険数理開発者が Azure とモデリング パッケージを組み合わせて使用して、リスクを分析する方法を見ていきます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-120">In this article, we will look at how actuarial developers can use Azure, coupled with modeling packages, to analyze risk.</span></span> <span data-ttu-id="f8c8e-121">記事では、Azure での大規模な実行のためにモデリング パッケージで使用される Azure テクノロジをいくつか説明します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-121">The article explains some of the Azure technologies the modeling packages use to run at scale on Azure.</span></span> <span data-ttu-id="f8c8e-122">これと同じテクノロジを使用して、ご利用のデータをさらに分析することができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-122">You can use the same technology to do further analysis of your data.</span></span> <span data-ttu-id="f8c8e-123">ここでは以下の項目について見ていきます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-123">We look at the following items:</span></span>

- <span data-ttu-id="f8c8e-124">Azure における、より短い時間でのより大規模なモデルの実行。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-124">Running larger models in less time, in Azure.</span></span>
- <span data-ttu-id="f8c8e-125">結果の報告。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-125">Reporting on the results.</span></span>
- <span data-ttu-id="f8c8e-126">データ保有期間の管理。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-126">Managing data retention.</span></span>

<span data-ttu-id="f8c8e-127">生命、損害、医療など、提供する保険の種類に関係なく、資産と負債の金融およびリスク モデルを作成し、投資と保険料を調整して、保険業者としての支払能力を維持する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-127">Whether you are servicing life, property and casualty, health, or other insurance, you need to create financial and risk models of your assets and liabilities to adjust your investments and premiums so that you stay solvent as an insurer.</span></span> <span data-ttu-id="f8c8e-128">IFRS 17 レポートでは、契約上のサービス マージン (CSM) の計算など、保険数理士が作成するモデルに変更が加えられています。これにより、保険業者の経時的な利益の管理方法が変わります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-128">IFRS 17 reporting adds changes to the models the actuaries create, like calculating the contractual service margin (CSM), which change how insurers manage their profit through time.</span></span>

## <a name="running-more-in-less-time-in-azure"></a><span data-ttu-id="f8c8e-129">Azure における、より短い時間でのより多くの実行</span><span class="sxs-lookup"><span data-stu-id="f8c8e-129">Running more in less time, in Azure</span></span>

<span data-ttu-id="f8c8e-130">クラウドの可能性を信じてください。金融およびリスク モデルをより迅速かつ簡単に実行することができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-130">You believe in the promise of the cloud: it can run your financial and risk models faster and easier.</span></span> <span data-ttu-id="f8c8e-131">多くの保険業者では、概算で問題が示されます。これらの計算を最初から最後まで順次行うのに数年、あるいは数十年も要します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-131">For many insurers, a back of the envelope calculation shows the problem: they need years, or even decades, of sequential time to run these calculations from start to finish.</span></span> <span data-ttu-id="f8c8e-132">実行時の問題を解決するためのテクノロジが必要です。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-132">You need technology to solve the runtime problem.</span></span> <span data-ttu-id="f8c8e-133">戦略は次のとおりです。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-133">Your strategies are:</span></span>

- <span data-ttu-id="f8c8e-134">データの準備:一部のデータは徐々に変化します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-134">Data preparation: Some data changes slowly.</span></span> <span data-ttu-id="f8c8e-135">ポリシーまたはサービス契約が実施されると、要求は予測可能なペースで移行します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-135">Once a policy or service contract is in force, claims move at a predictable pace.</span></span> <span data-ttu-id="f8c8e-136">データが到着したときにモデルの実行に必要なデータを準備できます。これにより、データのクレンジングと準備のために多くの時間をかける必要がなくなります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-136">You can prepare the data needed for model runs as it arrives, eliminating a need to plan much time for data cleansing and preparation.</span></span> <span data-ttu-id="f8c8e-137">また、クラスタリングを使用して、重み付け表現による連続データの代替を作成することもできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-137">You may also use clustering to create stand-ins for seriatim data through weighted representations.</span></span> <span data-ttu-id="f8c8e-138">通常、レコードの数が減ると、計算時間が短縮されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-138">Fewer records usually results in reduced computation time.</span></span>
- <span data-ttu-id="f8c8e-139">並列処理:2 つ以上の項目に対して同じ分析を行う必要がある場合は、同時に分析できることがあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-139">Parallelization: If you need to do the same analysis to two or more items, you may be able to perform the analysis simultaneously.</span></span>

<span data-ttu-id="f8c8e-140">これらの項目を個別に見てみましょう。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-140">Let's look at these items individually.</span></span>

### <a name="data-preparation"></a><span data-ttu-id="f8c8e-141">データの準備</span><span class="sxs-lookup"><span data-stu-id="f8c8e-141">Data Preparation</span></span>

<span data-ttu-id="f8c8e-142">データはいくつかの異なるソースから流入します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-142">Data flows in from several different sources.</span></span> <span data-ttu-id="f8c8e-143">業務書には半構造化されたポリシー データがあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-143">You have semi-structured policy data in your books of business.</span></span> <span data-ttu-id="f8c8e-144">被保険者、会社、およびさまざまなアプリケーション フォームに表示される項目に関する情報です。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-144">Information about the insured people, companies, and the items which appear in various application forms.</span></span> <span data-ttu-id="f8c8e-145">経済シナリオ ジェネレーター (ESG) では、モデルで使用できるフォームへの変換が必要な場合があるさまざまな形式のデータが生成されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-145">Economic Scenario Generators (ESGs) produce data in a variety of formats which may need translation to a form your model can use.</span></span> <span data-ttu-id="f8c8e-146">資産価値に関する現在のデータを正規化する必要もあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-146">Current data on values of assets also needs normalization.</span></span> <span data-ttu-id="f8c8e-147">株式市場データ、レンタルに関するキャッシュ フロー データ、住宅ローンに関する支払情報、およびその他の資産データをすべて、ソースからモデルへの移行時にある程度準備する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-147">The stock market data, cash flow data on rentals, payment information on mortgages, and other asset data all need some preparation when moving from the source to the model.</span></span> <span data-ttu-id="f8c8e-148">最後に、最近のエクスペリエンス データに基づいて、前提条件を更新する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-148">Finally, you should update any assumptions based on recent experience data.</span></span> <span data-ttu-id="f8c8e-149">モデルの実行を高速化するには、事前にデータを準備します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-149">To speed up a model run, you prepare the data ahead of time.</span></span> <span data-ttu-id="f8c8e-150">実行時間が発生したら、最後にスケジュールされた更新後の変更を加えるために必要な更新を行います。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-150">When run time happens, you do any necessary updates to add in changes since the last scheduled update.j</span></span>

<span data-ttu-id="f8c8e-151">ところで、データはどのように準備するのでしょうか。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-151">So, how do you prepare the data?</span></span> <span data-ttu-id="f8c8e-152">まず、一般的な例を見てみましょう。次に、データのさまざまな表示方法をどのように使用するのかを見ていきます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-152">Let's first look at the common bits and then look at how to work with the different ways data will appear.</span></span> <span data-ttu-id="f8c8e-153">まず、最後の同期以降に行われた変更をすべて取得するためのメカニズムが必要です。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-153">First, you want a mechanism to get all the changes since the last synchronization.</span></span> <span data-ttu-id="f8c8e-154">そのメカニズムでは、並べ替え可能な値を含める必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-154">That mechanism should include a value which is sortable.</span></span> <span data-ttu-id="f8c8e-155">最近の変更については、その値が以前の変更のものより大きくなければなりません。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-155">For recent changes, that value should be greater than any previous change.</span></span> <span data-ttu-id="f8c8e-156">2 つの最も一般的なメカニズムは、増え続ける ID フィールドやタイムスタンプです。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-156">The two most common two mechanisms are an ever-increasing ID field or a timestamp.</span></span> <span data-ttu-id="f8c8e-157">あるレコードの ID キーは増えているが、その他のレコードに更新可能なフィールドが含まれている場合、&quot;last-modified&quot; タイムスタンプなどを使用して、変更を見つける必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-157">If a record has an increasing ID key but the rest of the record contains fields which can be updated, you need to use something like a &quot;last-modified&quot; timestamp to find changes.</span></span> <span data-ttu-id="f8c8e-158">レコードが処理されたら、最後に更新された項目の並べ替え可能な値を記録します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-158">Once the records have been processed, record the sortable value of the last item updated.</span></span> <span data-ttu-id="f8c8e-159">この値 (おそらく、_lastModified_ というフィールドのタイムスタンプ) は指標になり、データ ストアの後続のクエリで使用されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-159">This value, probably a timestamp on a field called _lastModified_, becomes your watermark, used for subsequent queries on the data store.</span></span> <span data-ttu-id="f8c8e-160">データの変更はさまざまな方法で処理できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-160">Data changes can be processed in many ways.</span></span> <span data-ttu-id="f8c8e-161">最小限のリソースを使用する 2 つの一般的なメカニズムを以下に示します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-161">Here are two common mechanisms which use minimal resources:</span></span>

1. <span data-ttu-id="f8c8e-162">処理する変更が数百または数千件ある場合:データを BLOB ストレージにアップロードします。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-162">If you have hundreds or thousands of changes to process: Upload the data to blob storage.</span></span> <span data-ttu-id="f8c8e-163">[Azure Data Factory](https://docs.microsoft.com/azure/data-factory?WT.mc_id=riskmodel-docs-scseely) のイベント トリガーを使用して、変更セットを処理します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-163">Use an event trigger in [Azure Data Factory](https://docs.microsoft.com/azure/data-factory?WT.mc_id=riskmodel-docs-scseely) to process the changeset.</span></span>
2. <span data-ttu-id="f8c8e-164">プロセスの小さな変更セットがあるか、変更が発生したらすぐにデータを更新する場合は、[Service Bus](https://docs.microsoft.com/azure/service-bus-messaging?WT.mc_id=riskmodel-docs-scseely) または[ストレージ キュー](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction?WT.mc_id=riskmodel-docs-scseely)によってホストされるキュー メッセージに各変更を取り込みます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-164">If you have small sets of changes to process or want to update your data as soon as a change happens, put each change into a queue message hosted by [Service Bus](https://docs.microsoft.com/azure/service-bus-messaging?WT.mc_id=riskmodel-docs-scseely) or [Storage Queues](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-165">2 つのキュー テクノロジ間のトレードオフの詳細については、[こちらの記事](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted?WT.mc_id=riskmodel-docs-scseely)を参照してください。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-165">[This article](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted?WT.mc_id=riskmodel-docs-scseely) has a great explanation about the tradeoffs between the two queueing technologies.</span></span> <span data-ttu-id="f8c8e-166">メッセージがキューに取り込まれたら、Azure Functions または Azure Data Factory のトリガーを使用してメッセージを処理できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-166">Once a message is in a queue, you can use a trigger in Azure Functions or Azure Data Factory to process the message.</span></span>

<span data-ttu-id="f8c8e-167">以下の図に一般的なシナリオを示します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-167">The following figure illustrates a typical scenario.</span></span> <span data-ttu-id="f8c8e-168">まず、スケジュールされたジョブでいくつかのデータ セットが収集され、ファイルがストレージに配置されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-168">First, a scheduled job collects some set of data and places the file into storage.</span></span> <span data-ttu-id="f8c8e-169">スケジュールされたジョブには、オンプレミスで実行される CRON ジョブ、[Scheduler タスク](https://docs.microsoft.com/azure/scheduler?WT.mc_id=riskmodel-docs-scseely)、[Logic App](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=riskmodel-docs-scseely)、タイマーに基づいて実行されるものがあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-169">The scheduled job can be a CRON job running on premises, a [Scheduler task](https://docs.microsoft.com/azure/scheduler?WT.mc_id=riskmodel-docs-scseely), [Logic App](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=riskmodel-docs-scseely), or anything that runs on a timer.</span></span> <span data-ttu-id="f8c8e-170">ファイルがアップロードされたら、[Azure 関数](https://docs.microsoft.com/azure/azure-functions?WT.mc_id=riskmodel-docs-scseely)または **Data Factory** のインスタンスをトリガーしてデータを処理できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-170">Once the file is uploaded, an [Azure Function](https://docs.microsoft.com/azure/azure-functions?WT.mc_id=riskmodel-docs-scseely) or **Data Factory** instance can be triggered to process the data.</span></span> <span data-ttu-id="f8c8e-171">ファイルを短時間で処理できる場合は、**関数**を使用します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-171">If the file can be processed in a short period of time, use a **Function**.</span></span> <span data-ttu-id="f8c8e-172">処理が複雑で、AI またはその他の複合スクリプトが必要な場合、[HDInsight](https://docs.microsoft.com/azure/hdinsight?WT.mc_id=riskmodel-docs-scseely)、[Azure Databricks](https://docs.microsoft.com/azure/azure-databricks?WT.mc_id=riskmodel-docs-scseely)、またはカスタマイズされたものが適していることがあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-172">If the processing is complex, requires AI or other complex scripting, you may find that [HDInsight](https://docs.microsoft.com/azure/hdinsight?WT.mc_id=riskmodel-docs-scseely), [Azure Databricks](https://docs.microsoft.com/azure/azure-databricks?WT.mc_id=riskmodel-docs-scseely), or something custom works better.</span></span> <span data-ttu-id="f8c8e-173">完了すると、ファイルは、データベースのレコードとして、または新しいファイルとして使用可能なフォームになります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-173">When done, the file winds up in a usable form as a new file or as records in a database.</span></span>

 ![](./assets/insurance-risk-assets/process-files.png)

<span data-ttu-id="f8c8e-174">データが Azure に取り込まれたら、モデリング アプリケーションで使用できるようにする必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-174">Once the data is in Azure, you need to make it usable by the modeling application.</span></span> <span data-ttu-id="f8c8e-175">コードを書き込んでカスタム変換を行い、項目を **HDInsight** または Azure **Databricks** を介して実行し、より大きな項目を取り込んだり、データを適切なデータ セットにコピーしたりすることができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-175">You can write code to do custom transformations, run the items through **HDInsight** or Azure **Databricks** to ingest larger items, or copy the data into the right data sets.</span></span> <span data-ttu-id="f8c8e-176">ビッグ データ ツールの使用は、非構造化データから構造化データへの変換や受信データでの AI および ML の実行などにも役立つ場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-176">The use of big data tools can also help you do things like transform unstructured data into structured data as well as run any AI and ML over the received data.</span></span> <span data-ttu-id="f8c8e-177">また、仮想マシンのホスティング、オンプレミスからデータ ソースへのデータの直接アップロード、Azure Functions の直接呼び出しなどを行うことができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-177">You can also host virtual machines, upload data straight to data sources from on-premises, call Azure Functions directly, and so on.</span></span>

<span data-ttu-id="f8c8e-178">後で、データをモデルで使用する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-178">Later, the data needs to be consumed by your models.</span></span> <span data-ttu-id="f8c8e-179">これを行う方法は、計算でどのようにデータにアクセスする必要があるかに大きく依存します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-179">The way you do this depends largely on how the calculations need to access data.</span></span> <span data-ttu-id="f8c8e-180">一部のモデリング システムでは、すべてのデータ ファイルが、計算を行うノードに存在する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-180">Some modeling systems require all data files to live on the node that runs the calculation.</span></span> <span data-ttu-id="f8c8e-181">他のシステムでは、[Azure SQL Database](https://docs.microsoft.com/azure/sql-database/?WT.mc_id=riskmodel-docs-scseely)、[MySQL](https://docs.microsoft.com/azure/mysql/?WT.mc_id=riskmodel-docs-scseely)、[PostgreSQL](https://docs.microsoft.com/azure/postgresql/?WT.mc_id=riskmodel-docs-scseely) などのデータベースを利用できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-181">Others can make use of databases like [Azure SQL Database](https://docs.microsoft.com/azure/sql-database/?WT.mc_id=riskmodel-docs-scseely), [MySQL](https://docs.microsoft.com/azure/mysql/?WT.mc_id=riskmodel-docs-scseely), or [PostgreSQL](https://docs.microsoft.com/azure/postgresql/?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-182">これらの項目のいずれかの低コスト バージョンを使用し、モデリングの実行中にパフォーマンスを高めることができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-182">You can use a low-cost version of any of these items, and then scale up the performance during a modeling run.</span></span> <span data-ttu-id="f8c8e-183">これで、日常業務に必要な料金と、数千のコアでデータが要求されるときにだけ必要な追加速度がわかります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-183">This gives you the price you need for every day work, plus the extra speed just when thousands of cores are requesting data.</span></span> <span data-ttu-id="f8c8e-184">通常、モデリングの実行中はこのデータが読み取り専用になります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-184">Normally, this data will be read-only during a modeling run.</span></span> <span data-ttu-id="f8c8e-185">複数のリージョン間で計算を行う場合は、[Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/distribute-data-globally?WT.mc_id=riskmodel-docs-scseely) または [Azure SQL geo レプリケーション](https://docs.microsoft.com/azure/sql-database/sql-database-geo-replication-overview?WT.mc_id=riskmodel-docs-scseely)の使用を検討してください。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-185">If your calculations occur across multiple regions, consider using [Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/distribute-data-globally?WT.mc_id=riskmodel-docs-scseely) or [Azure SQL geo-replication](https://docs.microsoft.com/azure/sql-database/sql-database-geo-replication-overview?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-186">これらの両方では、短い待機時間でリージョン間でデータを自動的にレプリケートするためのメカニズムが提供されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-186">Both provide mechanisms to automatically replicate data across regions with low latency.</span></span> <span data-ttu-id="f8c8e-187">どちらを選ぶかは、開発者が認識しているツール、データのモデリング方法、モデリングの実行に使用されたリージョンの数によって決まります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-187">Your choice depends on the tools your developers know, how you have modeled your data, and the number of regions used for your modeling run.</span></span>

<span data-ttu-id="f8c8e-188">データの格納場所について考える時間を確保します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-188">Do spend some time thinking about where to store your data.</span></span> <span data-ttu-id="f8c8e-189">同じデータに対して存在する同時要求の数を把握します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-189">Understand how many simultaneous requests for the same data will exist.</span></span> <span data-ttu-id="f8c8e-190">情報を配布する方法について考えます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-190">Think about how you will distribute the information:</span></span>

- <span data-ttu-id="f8c8e-191">各コンピューティング ノードで独自のコピーを取得しますか。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-191">Does each computational node get its own copy?</span></span>
- <span data-ttu-id="f8c8e-192">コピーは何らかの高帯域幅の場所を介して共有されますか。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-192">Is the copy shared through some high bandwidth location?</span></span>

<span data-ttu-id="f8c8e-193">Azure SQL を使用してデータを集中管理し続けるのであれば、ほとんどの場合、より低い価格レベルでデータベースを保持することになります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-193">If you keep data centralized using Azure SQL, you will likely keep the database at a lower priced tier most of the time.</span></span> <span data-ttu-id="f8c8e-194">データがモデリングの実行時にのみ使用され、めったに更新されない場合、Azure のお客様はデータをバックアップし、実行と実行の間にデータベース インスタンスをオフにすることさえあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-194">If the data is only used during a modeling run and is not updated very often, Azure customers will go so far as to backup the data and turn off their database instances in between runs.</span></span> <span data-ttu-id="f8c8e-195">潜在的な節減額は多くなります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-195">The potential savings are large.</span></span> <span data-ttu-id="f8c8e-196">お客様は [Azure SQL エラスティック プール](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-pool?WT.mc_id=riskmodel-docs-scseely)を利用することもできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-196">Customers can also make use of [Azure SQL Elastic Pools](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-pool?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-197">これらは、特に異なる時間帯に大きな負荷がかかるデータベースを把握していない場合に、データベースのコストを制御するために設計されています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-197">These are designed to control database costs, especially when you do not know which databases will be under a lot of load at different times.</span></span> <span data-ttu-id="f8c8e-198">エラスティック プールでは、一連のデータベースで必要なだけ電力を使用し、システム内の別の場所に需要がシフトしたときにスケールバックできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-198">The elastic pools allow a collection of databases to use as much power as they need, then scale back once demand shifts elsewhere in the system.</span></span>

<span data-ttu-id="f8c8e-199">プロセスで後から計算するときに同じデータが使用されるように、モデルの実行時にデータ同期を無効にする必要がある場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-199">You may need to disable data synchronization during a modeling run so that calculations later in the process are using the same data.</span></span> <span data-ttu-id="f8c8e-200">キューを使用する場合は、メッセージ プロセッサを無効にしますが、キューでデータを受信できるようにします。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-200">If you are using queuing, disable the message processors but allow the queues to receive data.</span></span>

<span data-ttu-id="f8c8e-201">また、実行前の時間を利用して、経済シナリオを生成し、保険数理の前提条件を更新し、通常は他の静的データを更新することができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-201">You can also use the time before the run to generate economic scenarios, update actuarial assumptions, and generally update other static data.</span></span> <span data-ttu-id="f8c8e-202">それでは、経済シナリオ ジェネレーター (ESG) について見てみましょう。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-202">Let's look at economic scenario generation (ESG).</span></span> <span data-ttu-id="f8c8e-203">[アクチュアリー協会](https://www.soa.org/)では、米国債利回りをモデリングする ESG である、[Academy Interest Rate Generator](https://www.soa.org/tables-calcs-tools/research-scenario/) (AIRG)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-203">The [Society of Actuaries](https://www.soa.org/) provides the [Academy Interest Rate Generator](https://www.soa.org/tables-calcs-tools/research-scenario/) (AIRG), an ESG which models U. S.</span></span> <span data-ttu-id="f8c8e-204">が提供されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-204">Treasury yields.</span></span> <span data-ttu-id="f8c8e-205">AIRG は、評価マニュアル 20 (VM-20) 計算などの項目で使用するために規定されています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-205">AIRG is prescribed for use in items like Valuation Manual 20 (VM-20) calculations.</span></span> <span data-ttu-id="f8c8e-206">他の ESG では、株式市場、住宅ローン、商品価格などをモデリングする場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-206">Other ESGs may model the stock market, mortgages, commodity prices, and so on.</span></span>

<span data-ttu-id="f8c8e-207">ご利用の環境でデータを前処理するため、早い段階で他の部分を実行することもできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-207">Because your environment ispreprocessing the data, you can also run other pieces early.</span></span> <span data-ttu-id="f8c8e-208">たとえば、より多くの人口を表すレコードを使用するようにモデリングするとします。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-208">For example, you may have things which yv1ou model that use records to represent larger populations.</span></span> <span data-ttu-id="f8c8e-209">通常、これはレコードをクラスタリングすることで行います。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-209">One usually does this by clustering records.</span></span> <span data-ttu-id="f8c8e-210">1 日 1 回など、散発的にデータセットが更新される場合、レコード セットを、取り込みプロセスの一部としてモデルで使用されるものに減らすことができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-210">If the dataset is updated sporadically, such as once a day, one can reduce the record set to what will be used in the model as part of the ingestion process.</span></span>

<span data-ttu-id="f8c8e-211">実例を見てましょう。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-211">Let's look at a practical example.</span></span> <span data-ttu-id="f8c8e-212">IFRS-17 を使用して、2 つの契約の開始日の間隔が最長で 1 年未満になるように、契約をまとめてグループ化する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-212">With IFRS-17, you need to group your contracts together such that the maximum distance between the start dates for any two contracts is under one year.</span></span> <span data-ttu-id="f8c8e-213">これを簡単な方法で行い、グループ化メカニズムとして契約年を使用するとします。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-213">Let's assume that you do this the easy way and use the contract year as the grouping mechanism.</span></span> <span data-ttu-id="f8c8e-214">このセグメント化は、ファイルに目を通し、レコードを適切な年グループに移動することで、データが Azure に読み込まれる間に行うことができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-214">This segmentation can be done while data is loaded into Azure by reading through the file and moving the records to the appropriate year groupings.</span></span>

<span data-ttu-id="f8c8e-215">データの準備に重点を置くことで、モデル コンポーネントの実行に必要な時間が短縮されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-215">Focusing on data preparation reduces the time necessary to run the model components.</span></span> <span data-ttu-id="f8c8e-216">早い段階でデータを取得することで、モデルの実行時間を節約できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-216">By getting the data in early, you can save clock time for running your models.</span></span>

### <a name="parallelization"></a><span data-ttu-id="f8c8e-217">並列処理</span><span class="sxs-lookup"><span data-stu-id="f8c8e-217">Parallelization</span></span>

<span data-ttu-id="f8c8e-218">ステップの適切な並列処理により、実行時間 (クロック時間) を大幅に短縮できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-218">Proper parallelization of the steps can shrink clock execution time dramatically.</span></span> <span data-ttu-id="f8c8e-219">この高速化は、実装する部分を効率化し、2 つ以上のアクティビティを同時に実行できる方法でモデルを表現する方法を把握することで実現できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-219">This speedup happens by streamlining the pieces that you implement and knowing how to express your model in a way that allows for two or more activities to run simultaneously.</span></span> <span data-ttu-id="f8c8e-220">その際のこつは、作業要求のサイズと、個々のノードの生産性との間のバランスを見つけることです。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-220">The trick is to find balance between the size of the work request and the productivity of an individual node.</span></span> <span data-ttu-id="f8c8e-221">タスクで評価よりセットアップとクリーンアップに長い時間がかかる場合、小さすぎます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-221">If the task spends more time in setup and cleanup than it does in evaluation, you went too small.</span></span> <span data-ttu-id="f8c8e-222">タスクが大きすぎる場合、実行時間は改善されません。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-222">If the task is too large, execution time does not improve.</span></span> <span data-ttu-id="f8c8e-223">アクティビティを、複数のノードに分散させ、実行経過時間に効果が見られるくらい十分小さくする必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-223">You want the activity to be small enough to spread over multiple nodes and make a positive difference in elapsed execution time.</span></span>

<span data-ttu-id="f8c8e-224">システムを最大限に活用するには、モデルのワークフローと、計算でスケールアウトの機能を操作する方法を理解する必要があります。ソフトウェアにはジョブやタスクなどの概念がある場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-224">To get the most out of your system, you need to understand the workflow for your model and how the computations interact with the ability to scale out. Your software may have a notion of jobs, tasks, or something similar.</span></span> <span data-ttu-id="f8c8e-225">その知識を活かして、作業を分割できるものを設計します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-225">Use that knowledge to design something that can split work up.</span></span> <span data-ttu-id="f8c8e-226">モデルにいくつかのカスタム ステップがある場合は、入力をより小さい処理グループに分割できるように設計します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-226">If you have some custom steps in your model, design those to allow for inputs to be split into smaller groups for processing.</span></span> <span data-ttu-id="f8c8e-227">多くの場合、これをスキャッター/ギャザー パターンといいます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-227">Oftentimes, this is referred to as a scatter-gather pattern.</span></span>

- <span data-ttu-id="f8c8e-228">スキャッター:自然な線に沿って入力を分割し、個別のタスクを実行できるようにします。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-228">Scatter: Split the inputs along natural lines and allow separate tasks to run.</span></span>
- <span data-ttu-id="f8c8e-229">ギャザー:タスクが完了したときに、それらの出力を収集します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-229">Gather: As the tasks complete, collect their outputs.</span></span>

<span data-ttu-id="f8c8e-230">また、分割時に、プロセスを同期する必要がある場所を確認してから先に進みます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-230">When splitting things, also know where the process needs to synchronize before moving forward.</span></span> <span data-ttu-id="f8c8e-231">一般的な分割場所はいくつかあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-231">There are a few common places people split things up.</span></span> <span data-ttu-id="f8c8e-232">入れ子になった確率的実行の場合、100 個のシナリオの内部ループを実行する一連の変曲点がある 1,000 個の外部ループが存在する場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-232">For nested stochastic runs, you may have a thousand outer loops with a set of inflection points that run inner loops of one hundred scenarios.</span></span> <span data-ttu-id="f8c8e-233">各外部ループは同時に実行できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-233">Each outer loop can run simultaneously.</span></span> <span data-ttu-id="f8c8e-234">変曲点で止め、内部ループを同時に実行し、外部ループ用にデータを調整するために情報を戻し、再び先に進みます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-234">You halt at an inflection point, then run the inner loops simultaneously, bring the information back to adjust the data for the outer loop, and go forward again.</span></span> <span data-ttu-id="f8c8e-235">次の図にワークフローを示します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-235">The following figure demonstrates illustrates the workflow.</span></span> <span data-ttu-id="f8c8e-236">十分なコンピューティングであれば、100,000 個のコアで 100,000 個の内部ループを実行でき、処理時間は次の時間の合計になります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-236">Given enough compute, you can run the 100,000 inner loops on 100,000 cores, bringing processing time down to the sum of the following times:</span></span>

![](./assets/insurance-risk-assets/timing.png)

<span data-ttu-id="f8c8e-237">方法に応じて、配布は若干増えます。つまり、適切なパラメーターを指定した小さなジョブを作成するだけのシンプルなものになる場合や、適切な場所に 100K ファイルをコピーするくらい複雑なものになる場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-237">Distribution will increase a bit depending on how that is done; it may be as simple as constructing a small job with the right parameters or as complex as copying 100K files to the right places.</span></span> <span data-ttu-id="f8c8e-238">HD Insight の Apache Spark、Azure Databricks、または独自のデプロイ環境を使用して結果集計を配布できる場合は、結果の処理をさらに高速化できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-238">Processing results can even be sped up if you can distribute the result aggregation using Apache Spark from HD Insight, Azure Databricks, or your own deployment.</span></span> <span data-ttu-id="f8c8e-239">たとえば、平均の計算は、これまでの項目数と合計を記憶しておくだけの簡単な処理です。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-239">For example, computing averages is a simple matter of remembering the number of items seen so far and the sum.</span></span> <span data-ttu-id="f8c8e-240">その他の計算は、数千個のコアを備えた単一コンピューターに適している場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-240">Other computations may work better on a single machine with thousands of cores.</span></span> <span data-ttu-id="f8c8e-241">その場合、Azure で GPU 対応のコンピューターを利用できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-241">For those, you can make use of GPU enabled machines in Azure.</span></span>

<span data-ttu-id="f8c8e-242">ほとんどの保険数理チームは、モデルを Azure に移行することから開始します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-242">Most actuarial teams start this journey by moving their models to Azure.</span></span> <span data-ttu-id="f8c8e-243">その後、プロセスにおけるさまざまなステップに関するタイミング データを収集します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-243">They then collect timing data on the various steps in the process.</span></span> <span data-ttu-id="f8c8e-244">次に、最長経過時間から最短経過時間までのステップごとのクロック時間を並べ替えます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-244">They then sort the clock time for each step from longest to shortest elapsed time.</span></span> <span data-ttu-id="f8c8e-245">数千のコア時間が使用される可能性はあるが、経過時間が 20 分のみであるため、総実行時間は確認しません。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-245">They will not look at total execution time since something may consume thousands of core hours but only 20 minutes elapsed time.</span></span> <span data-ttu-id="f8c8e-246">最も長く実行されている各ジョブ ステップについては、保険数理開発者は、正しい結果を得ながら、経過時間を減らす方法を模索します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-246">For each of the longest running job steps, the actuarial developers look for ways to decrease the elapsed time while getting the right results.</span></span> <span data-ttu-id="f8c8e-247">このプロセスは定期的に繰り返されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-247">This process repeats regularly.</span></span> <span data-ttu-id="f8c8e-248">一部の保険数理チームではターゲットの実行時間を設定します。つまり、夜間のヘッジ分析を 8 時間未満で行うことが目標となります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-248">Some actuarial teams will set a target run time, let's say an overnight hedging analysis has a goal of running in under 8 hours.</span></span> <span data-ttu-id="f8c8e-249">この時間が 8.25 時間に近づくとすぐに、保険数理チームの一部が、分析の最も長い部分の時間を改善するために切り替えられます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-249">As soon as the time creeps over 8.25 hours, some part of the actuarial team will switch over to improve the time of the longest piece in the analysis.</span></span> <span data-ttu-id="f8c8e-250">時間が 7.5 時間未満に戻った場合、開発に戻ります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-250">Once they get the time back under 7.5 hours, they switch back to development.</span></span> <span data-ttu-id="f8c8e-251">元に戻り、最適化するためのヒューリスティックは保険数理士によって異なります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-251">The heuristics to go back and optimize vary amongst actuaries.</span></span>

<span data-ttu-id="f8c8e-252">これをすべて実行するための、いくつかのオプションがあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-252">To run all this, you have several options.</span></span> <span data-ttu-id="f8c8e-253">ほとんどの保険数理ソフトウェアは、コンピューティング グリッドで動作します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-253">Most actuarial software works with compute grids.</span></span> <span data-ttu-id="f8c8e-254">オンプレミスおよび Azure で動作するグリッドでは、[HPC Pack](https://docs.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options?WT.mc_id=riskmodel-docs-scseely)、サード パーティのパッケージ、またはカスタマイズされたものが使用されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-254">Grids that work on-premises and on Azure use either [HPC Pack](https://docs.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options?WT.mc_id=riskmodel-docs-scseely), a third party package, or something custom.</span></span> <span data-ttu-id="f8c8e-255">Azure 用に最適化されたグリッドでは、[Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/?WT.mc_id=riskmodel-docs-scseely)、[Batch](https://docs.microsoft.com/azure/batch/?WT.mc_id=riskmodel-docs-scseely)、またはカスタマイズされたものが使用されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-255">Grids optimized for Azure will use [Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/?WT.mc_id=riskmodel-docs-scseely), [Batch](https://docs.microsoft.com/azure/batch/?WT.mc_id=riskmodel-docs-scseely), or something custom.</span></span> <span data-ttu-id="f8c8e-256">Scale Sets または Batch を使用することにした場合は、必ず、低優先度 VM のサポート ([Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-low-priority?WT.mc_id=riskmodel-docs-scseely) の低優先度に関するドキュメント、[Batch](https://docs.microsoft.com/azure/batch/batch-low-pri-vms?WT.mc_id=riskmodel-docs-scseely) の低優先度に関するドキュメント) を確認してください。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-256">If you choose to use either Scale Sets or Batch, make sure to look at their support for low priority VMs ([Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-low-priority?WT.mc_id=riskmodel-docs-scseely) low priority docs, [Batch](https://docs.microsoft.com/azure/batch/batch-low-pri-vms?WT.mc_id=riskmodel-docs-scseely) low priority docs).</span></span> <span data-ttu-id="f8c8e-257">低優先度 VM とは、通常価格の何分の 1 かでレンタルできる、ハードウェアで実行される VM のことです。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-257">A low priority VM is a VM running on hardware which you can rent for a fraction of the normal price.</span></span> <span data-ttu-id="f8c8e-258">低優先度 VM は容量要求時に割り込まれる可能性があるため、より低価格で利用できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-258">The lower price is available because low priority VMs may be preempted when capacity demands it.</span></span> <span data-ttu-id="f8c8e-259">時間予算にある程度余裕がある場合、低優先度 VM では、モデリングの実行の価格を下げるための優れた方法が提供されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-259">If you have some wiggle room in your time budget, the low priority VMs provide a great way to reduce the price of a modeling run.</span></span>

<span data-ttu-id="f8c8e-260">多くのコンピューター (おそらく、さなざまなリージョンで実行されているものを含む) で実行およびデプロイを調整する必要がある場合、CycleCloud を利用できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-260">If you need to coordinate the execution and deployment across many machines, perhaps with some running in different regions, you can take advantage of CycleCloud.</span></span> <span data-ttu-id="f8c8e-261">CycleCloud では追加コストは発生しません。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-261">CycleCloud costs nothing extra.</span></span> <span data-ttu-id="f8c8e-262">必要に応じて、データ移動が調整されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-262">It orchestrates data movement when necessary.</span></span> <span data-ttu-id="f8c8e-263">これには、コンピューターの割り当て、監視、シャットダウンが含まれます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-263">This includes allocation, monitoring, and shut down of the machines.</span></span> <span data-ttu-id="f8c8e-264">低優先度コンピューターを処理することもでき、確実にその費用は含まれます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-264">It can even handle low priority machines, making sure expenses are contained.</span></span> <span data-ttu-id="f8c8e-265">必要なコンピューターの組み合わせを説明することさえできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-265">You can go so far as to describe the mix of machines you need.</span></span> <span data-ttu-id="f8c8e-266">たとえば、おそらくコンピューター クラスが必要ですが、2 つ以上のコアを備えた任意のバージョンでも正常に実行できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-266">For example, maybe you need a class of machine but can run well on any version that has 2 or more cores.</span></span> <span data-ttu-id="f8c8e-267">Cycle ではこれらのコンピューターの種類でコアを割り当てることができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-267">Cycle can allocate cores across those machine types.</span></span>

## <a name="reporting-on-the-results"></a><span data-ttu-id="f8c8e-268">結果の報告</span><span class="sxs-lookup"><span data-stu-id="f8c8e-268">Reporting on the Results</span></span>

<span data-ttu-id="f8c8e-269">保険数理パッケージが実行され、その結果が生成されたら、いくつかの規制レポートが準備できています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-269">Once the actuarial packages have run and produced their results, you will have several regulator ready reports.</span></span> <span data-ttu-id="f8c8e-270">規制者や監査員が必要としない分析情報を生成するために分析できる新しいデータも山ほどあります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-270">You will also have a mountain of new data that you may want to analyze to generate insights not required by regulators or auditors.</span></span> <span data-ttu-id="f8c8e-271">最適な顧客のプロファイルを理解することができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-271">You may want to understand the profile of your best customers.</span></span> <span data-ttu-id="f8c8e-272">分析情報を使用して、低コスト顧客がどのようなものであるかをマーケティング部に伝え、マーケティング部と販売部でそれらをより早く見つけられるようにします。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-272">Using insights, you can tell marketing what a low-cost customer looks like so that marketing and sales can find them faster.</span></span> <span data-ttu-id="f8c8e-273">同様に、データを使用して、保険に加入することで最も利益が得られるグループを見つけることができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-273">Likewise, you can use the data to discover which groups benefit the most from having the insurance.</span></span> <span data-ttu-id="f8c8e-274">たとえば、初期段階の健康問題をより早く発見できる年に一度の身体検査を利用する人が見つかる場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-274">For example, you may discover that people who take advantage of an annual physical found out about early stage health issues earlier.</span></span> <span data-ttu-id="f8c8e-275">これにより、保険会社の時間とコストが節約されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-275">This saves the insurance company time and money.</span></span> <span data-ttu-id="f8c8e-276">そのデータを使用して、顧客ベースの行動を駆り立てることができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-276">You can use that data to drive behavior in your customer base.</span></span>

<span data-ttu-id="f8c8e-277">これを行うには、多くのデータ サイエンス ツールと、視覚化のための一部のデータへのアクセスが必要です。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-277">To do this, you will want access to plenty of data science tooling as well as some pieces for visualization.</span></span> <span data-ttu-id="f8c8e-278">どの程度の調査を行うかに応じて、[データ サイエンス VM](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview?WT.mc_id=riskmodel-docs-scseely) から開始できます。この VM は Azure Marketplace からプロビジョニングできます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-278">Depending on how much investigation you want to do, you can start with [a Data Science VM](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview?WT.mc_id=riskmodel-docs-scseely) which can be provisioned from the Azure Marketplace.</span></span> <span data-ttu-id="f8c8e-279">これらの VM には、Windows 版と Linux 版の両方があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-279">These VMs have both Windows and Linux versions.</span></span> <span data-ttu-id="f8c8e-280">インストールしたら、Microsoft R Open、Microsoft ML Server、Anaconda、Jupyter、およびその他のツールの準備が整います。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-280">Installed, you will find Microsoft R Open, Microsoft ML Server, Anaconda, Jupyter, and other tools ready to go.</span></span> <span data-ttu-id="f8c8e-281">R または Python を少し挿入して、データを視覚化し、同僚と分析情報を共有します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-281">Throw in a little R or Python to visualize the data and share insights with your colleagues.</span></span>

<span data-ttu-id="f8c8e-282">さらに分析を行う必要がある場合は、HDInsight または Databricks を介して、Spark や Hadoop などの Apache データ サイエンス ツールを使用できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-282">If you need to do more analysis, you can use Apache data science tools like Spark, Hadoop, and others via either HDInsight or Databricks.</span></span> <span data-ttu-id="f8c8e-283">分析を定期的に行う必要があり、ワークフローを自動化する場合にもこれらを使用します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-283">Use these more for when the analysis needs to be done regularly and you want to automate the workflow.</span></span> <span data-ttu-id="f8c8e-284">これは、大規模なデータセットのライブ分析にも役立ちます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-284">This is also useful for live analysis of large datasets.</span></span>

<span data-ttu-id="f8c8e-285">何か興味深いものが見つかったら、結果を示す必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-285">Once you have found something interesting, you need to present the results.</span></span> <span data-ttu-id="f8c8e-286">多くの保険数理士は、まず、サンプルの結果を使用し、Excel に取り込んでチャート、グラフ、およびその他の視覚エフェクトを作成します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-286">Many actuaries will start by taking the sample results and plugging them into Excel to create charts, graphs, and other visualizations.</span></span> <span data-ttu-id="f8c8e-287">データを詳しく調べるのに適したインターフェイスを備えたものが必要な場合は、[Power BI](https://docs.microsoft.com/power-bi/?WT.mc_id=riskmodel-docs-scseely) を確認してください。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-287">If you want something that also has a nice interface for drilling into the data, take a look at [Power BI](https://docs.microsoft.com/power-bi/?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-288">Power BI ではいくつかの適した視覚エフェクトを作成し、ソース データを表示できます。また、[順序付けられ、注釈の付いたブックマーク](https://docs.microsoft.com/power-bi/desktop-bookmarks?WT.mc_id=riskmodel-docs-scseely)を追加することで、閲覧者にデータを説明することができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-288">Power BI can make some nice visualizations, display the source data, and it allows for explaining the data to the reader through the addition of [ordered, annotated bookmarks](https://docs.microsoft.com/power-bi/desktop-bookmarks?WT.mc_id=riskmodel-docs-scseely).</span></span>

## <a name="data-retention"></a><span data-ttu-id="f8c8e-289">データ保有期間</span><span class="sxs-lookup"><span data-stu-id="f8c8e-289">Data Retention</span></span>

<span data-ttu-id="f8c8e-290">システムに取り込むデータの多くは、将来の監査のために保持する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-290">Much of the data you bring into the system needs to be preserved for future audits.</span></span> <span data-ttu-id="f8c8e-291">データ保有期間要件の範囲は、通常、7 年から 10 年ですが、この要件は変わります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-291">Data retention requirements typically range from 7 to 10 years, but requirements vary.</span></span> <span data-ttu-id="f8c8e-292">最小保有期間の対象は以下のとおりです。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-292">Minimal retention involves:</span></span>

- <span data-ttu-id="f8c8e-293">モデルへの元の入力のスナップショット。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-293">Snapshot of the original inputs to the model.</span></span> <span data-ttu-id="f8c8e-294">これには資産、負債、前提条件、ESG、およびその他の入力が含まれます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-294">This includes assets, liabilities, assumptions, ESGs, and other inputs.</span></span>
- <span data-ttu-id="f8c8e-295">最終的な出力のスナップショット。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-295">Snapshot of the final outputs.</span></span> <span data-ttu-id="f8c8e-296">これには、規制機関に提示するレポートを作成するために使用されたすべてのデータが含まれます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-296">This includes any data used to create reports presented to regulatory bodies.</span></span>
- <span data-ttu-id="f8c8e-297">その他の重要な中間結果。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-297">Other important, intermediate results.</span></span> <span data-ttu-id="f8c8e-298">監査員は、モデルで何らかの結果が得られた理由をたずねます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-298">An auditor will ask why your model came up with some result.</span></span> <span data-ttu-id="f8c8e-299">モデルである選択を行った、あるいは特定の数値が得られた理由に関する証拠を保持する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-299">You need to retain evidence about why the model made certain choices or came up with particular numbers.</span></span> <span data-ttu-id="f8c8e-300">多くの保険業者は、元の入力から最終出力を生成するために使用されたバイナリを保持することを選択します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-300">Many insurers will choose to keep the binaries used to produce the final outputs from the original inputs.</span></span> <span data-ttu-id="f8c8e-301">その後、たずねられたときに、モデルを再実行し、中間結果の最新コピーを取得します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-301">Then, when questioned, they rerun the model to get a fresh copy of the intermediate results.</span></span> <span data-ttu-id="f8c8e-302">出力が一致した場合、中間ファイルに必要な説明も含める必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-302">If the outputs match, then the intermediate files should also contain the explanations they need.</span></span>

<span data-ttu-id="f8c8e-303">モデルの実行中に、保険数理士は、実行からの要求負荷を処理できるデータ配信メカニズムを使用します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-303">During the model run, the actuaries use data delivery mechanisms that can handle the request load from the run.</span></span> <span data-ttu-id="f8c8e-304">実行が完了し、データが不要になったら、データの一部を保持します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-304">Once the run is complete and data is no longer needed, they preserve some of the data.</span></span> <span data-ttu-id="f8c8e-305">少なくとも、保険業者は、再現性要件の実行時構成と入力を保持する必要があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-305">At a minimum, an insurer should preserve the inputs and the runtime configuration for any reproducibility requirements.</span></span> <span data-ttu-id="f8c8e-306">データベースは Azure Blob Storage 内のバックアップに保持され、サーバーはシャットダウンされます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-306">Databases are preserved to backups in Azure Blob Storage and servers are shut down.</span></span> <span data-ttu-id="f8c8e-307">高速ストレージ上のデータも、より低コストの Azure Blob Storage に移行されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-307">Data on high speed storage also moves to the less expensive Azure Blob Storage.</span></span> <span data-ttu-id="f8c8e-308">Blob Storage に移行されたら、各 BLOB で使用するデータ層 (ホット、クール、アーカイブ) を選択できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-308">Once in Blob Storage, you can choose the data tier used for each blob: hot, cool, or archive.</span></span> <span data-ttu-id="f8c8e-309">ホット ストレージは、頻繁にアクセスされるファイルに適しています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-309">Hot storage works well for frequently accessed files.</span></span> <span data-ttu-id="f8c8e-310">クール ストレージは、頻度の低いデータ アクセス用に最適化されています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-310">Cool storage is optimized for infrequent data access.</span></span> <span data-ttu-id="f8c8e-311">アーカイブ ストレージは監査可能なファイルを保持するのに最適です。しかし、価格の割引により待機時間コストが発生します。アーカイブ層のデータ待機時間は時間単位で測定されます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-311">Archive storage is best for holding auditable files but the price savings comes at a latency cost: archived tier data latency is measured in hours.</span></span> <span data-ttu-id="f8c8e-312">「[Azure Blob Storage:ホット、クール、アーカイブ ストレージ層](https://docs.microsoft.com/azure/storage/blobs/storage-blob-storage-tiers?WT.mc_id=riskmodel-docs-scseely)」をお読みになり、さまざまなストレージ層についてよく理解してください。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-312">Read [Azure Blob storage: Hot, cool, and archive storage tiers](https://docs.microsoft.com/azure/storage/blobs/storage-blob-storage-tiers?WT.mc_id=riskmodel-docs-scseely) to fully understand the different storage tiers.</span></span> <span data-ttu-id="f8c8e-313">ライフサイクル管理により、データを作成して削除するまでの管理を行うことができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-313">You can manage data from creation through deletion with lifecycle management.</span></span> <span data-ttu-id="f8c8e-314">BLOB の URI はそのままですが、BLOB の格納場所については、時間の経過と共にコストが低くなります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-314">URIs for blobs stay static, but where the blob is stored gets cheaper over time.</span></span> <span data-ttu-id="f8c8e-315">この機能により、Azure Storage の多くのユーザーはコストを大幅に節約でき、頭痛の種を取り除くことができます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-315">This feature will save a lot of money and headaches for many users of Azure Storage.</span></span> <span data-ttu-id="f8c8e-316">[Azure Blob Storage のライフサイクルの管理](https://docs.microsoft.com/azure/storage/common/storage-lifecycle-managment-concepts?WT.mc_id=riskmodel-docs-scseely)に関するページで、入力と出力について学習できます。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-316">You can learn about the ins and outs in [Managing the Azure Blob Storage Lifecycle](https://docs.microsoft.com/azure/storage/common/storage-lifecycle-managment-concepts?WT.mc_id=riskmodel-docs-scseely).</span></span> <span data-ttu-id="f8c8e-317">自動的にファイルを削除できるのはすばらしいことです。つまり、ファイル自体を自動的に削除できるため、スコープ外のファイルを参照し、誤って監査を拡張することがなくなります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-317">The fact that you can automatically delete files is wonderful: it means that you won't accidentally expand an audit by referring to a file that is out of scope because the file itself can be removed automatically.</span></span>

## <a name="next-steps"></a><span data-ttu-id="f8c8e-318">次の手順</span><span class="sxs-lookup"><span data-stu-id="f8c8e-318">Next steps</span></span>

<span data-ttu-id="f8c8e-319">実行する保険数理システムにオンプレミス グリッドの実装がある場合、そのグリッドの実装は Azure でも実行される可能性があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-319">If the actuarial system you run has a on premises grid implementation, that grid implementation will likely run on Azure too.</span></span> <span data-ttu-id="f8c8e-320">一部のベンダーでは、ハイパースケールで実行される Azure 実装が特殊化されています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-320">For some vendors, they have specialized Azure implementations that run at hyperscale.</span></span> <span data-ttu-id="f8c8e-321">Azure への移行時に、内部ツールも移行します。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-321">As part of the move to Azure, move your internal tooling over as well.</span></span> <span data-ttu-id="f8c8e-322">どこの保険数理士も、データ サイエンス スキルがラップトップや大規模な環境に適していることに気付いています。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-322">Actuaries everywhere have been finding that their data science skills work well on their laptop or with a large environment.</span></span> <span data-ttu-id="f8c8e-323">チームで既に行ったものを見つけます。おそらく、ディープ ラーニングを使用するが、1 つの GPU で実行するのに数時間または数日かかるものです。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-323">Look for things your team already does: maybe you have something that uses deep learning but takes hours or days to run on one GPU.</span></span> <span data-ttu-id="f8c8e-324">4 つのハイエンド GPU を備えたコンピューター上で同じワークロードを実行してみて、実行時間を確認します。既存のものであれば、大幅な高速化となる可能性は十分あります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-324">Try running the same workload on a machine with 4 high end GPUs and look at the run times; odds are good you will see significant speedups for things you already have.</span></span>

<span data-ttu-id="f8c8e-325">改善されたら、必ず、データ同期を構築し、モデリング データのフィードも行ってください。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-325">As things improve, make sure that you also build out some data synchronization to feed the modeling data.</span></span> <span data-ttu-id="f8c8e-326">データが準備できるまで、モデルの実行を開始することはできません。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-326">A model run cannot start until the data is ready.</span></span> <span data-ttu-id="f8c8e-327">変更されたデータのみを送信するために、多少の手間がかかる場合があります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-327">This may involve adding some effort so that you send only data which has changed.</span></span> <span data-ttu-id="f8c8e-328">実際の方法は、データ サイズにも依存します。つまり、数 MB の更新はおそらくたいしたことではありませんが、数ギガバイトのアップロードを減らすことは大幅な高速化になります。</span><span class="sxs-lookup"><span data-stu-id="f8c8e-328">The actual approach depends on the data size too: updating a few MB maybe isn't a big deal but reducing the number of gigabyte uploads will speed things a lot.</span></span>

### <a name="tutorials"></a><span data-ttu-id="f8c8e-329">チュートリアル</span><span class="sxs-lookup"><span data-stu-id="f8c8e-329">Tutorials</span></span>

- <span data-ttu-id="f8c8e-330">R 開発者: [Azure Batch で並列 R シミュレーションを実行する](https://docs.microsoft.com/azure/batch/tutorial-r-doazureparallel?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-330">R Developers: [Run a parallel R simulation with Azure Batch](https://docs.microsoft.com/azure/batch/tutorial-r-doazureparallel?WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="f8c8e-331">Azure 関数を使用してストレージを操作する方法を説明するチュートリアル:[Azure Functions を使用して BLOB ストレージに画像をアップロードする](https://docs.microsoft.com/azure/functions/tutorial-static-website-serverless-api-with-database?tutorial-step=2&WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-331">Tutorial to show how to use an Azure Function to interact with storage: [Upload images to Blob storage with Azure Functions](https://docs.microsoft.com/azure/functions/tutorial-static-website-serverless-api-with-database?tutorial-step=2&WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="f8c8e-332">Databricks を使用した ETL:[Azure Databricks を使ったデータの抽出、変換、読み込み](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-332">ETL with Databricks: [Extract, transform, and load data using Azure Databricks](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse?WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="f8c8e-333">HDInsight を使用した ETL:[Azure HDInsight の Apache Hive を使用してデータの抽出、変換、読み込みを行う](https://docs.microsoft.com/azure/hdinsight/hdinsight-analyze-flight-delay-data-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fhadoop%2FTOC.json&amp;bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json&WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-333">ETL with HDInsight: [Extract, transform, and load data using Apache Hive on Azure HDInsight](https://docs.microsoft.com/azure/hdinsight/hdinsight-analyze-flight-delay-data-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fhadoop%2FTOC.json&amp;bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json&WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="f8c8e-334">データ サイエンス VM の使用方法 (Linux): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-334">Data Science VM How To (Linux): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough?WT.mc_id=riskmodel-docs-scseely)</span></span>
- <span data-ttu-id="f8c8e-335">データ サイエンス VM の使用方法 (Windows): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things?WT.mc_id=riskmodel-docs-scseely)</span><span class="sxs-lookup"><span data-stu-id="f8c8e-335">Data Science VM How To (Windows): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things?WT.mc_id=riskmodel-docs-scseely)</span></span>
