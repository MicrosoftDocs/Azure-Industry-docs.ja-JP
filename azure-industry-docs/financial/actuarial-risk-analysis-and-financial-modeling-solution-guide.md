---
title: 保険数理リスク分析とモデリングのソリューション ガイド
author: scseely
ms.author: scseely
ms.date: 08/23/2018
ms.topic: article
ms.service: industry
description: このソリューション ガイドでは、保険数理開発者が既存のソリューションとサポート インフラストラクチャを Azure にどのように移行できるかについて説明します。
ms.openlocfilehash: 82cb53d529f6d7524ae1f9c148118b5edddc648b
ms.sourcegitcommit: 76f2862adbec59311b5888e043a120f89dc862af
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/03/2018
ms.locfileid: "51654289"
---
# <a name="actuarial-risk-analysis-and-financial-modeling-solution-guide"></a>保険数理リスク分析と金融モデリングのソリューション ガイド

ここ数年にわたり、保険関連商品を提供する保険業者および会社では、いくつかの新しい規制が施行されていることを認識しています。 これらの新しい規制では、保険業者のより広範な金融モデリングが求められます。 欧州連合で制定された[ソルベンシー II](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) では、保険業者は年末における支払能力を確認するために適切な分析を行ったことを示すよう求められます。 変額年金を提供する保険業者は、資産および負債キャッシュ フローの広範な分析に関する[保険数理ガイドライン XLIII](https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex%3A32009L0138) に従う必要があります。 保険関連商品を配布する業者を含め、すべての種類の保険業者は、2021 年までに[国際財務報告基準 17](https://www.ifrs.org/supporting-implementation/supporting-materials-by-ifrs-standard/ifrs-17/) (IFRS 17) を実装する必要があります。 保険業者が担当する管轄に応じて、その他の規制が存在します。 これらの標準や規制では、保険数理士は資産および負債のモデリング時にコンピューティング集中型手法を使用することが求められます。 ほとんどの分析で、資産および負債などの連続入力について確率的に生成されたシナリオ データが利用されます。 保険数理士は、規制で求められるものよりはるかに多くの金融モデリングと計算を行い、規制レポートを生成するモデルの入力テーブルを作成します。 内部グリッドではコンピューティング ニーズが満たされないため、保険数理士は徐々にクラウドに移行しています。

保険数理士はクラウドに移行することで、結果の確認、評価、検証のためにより多くの時間を確保することができます。 規制機関によって保険業者の監査が行われる際に、保険数理士はその結果を説明できる必要があります。 クラウドに移行することで、並列処理を利用して 24 時間から 120 時間 (クロック時間) で 20,000 時間の分析を行うためのコンピューティング リソースにアクセスできます。 このようなスケールのニーズを満たせるように、保険数理ソフトウェアを作成する企業の多くでは、Azure で計算を行うことができるソリューションが提供されます。 これらのソリューションの一部は、[HPC Pack](https://docs.microsoft.com/powershell/high-performance-computing/overview?view=hpc16-ps&WT.mc_id=riskmodel-docs-scseely) などの Azure およびオンプレミスで実行されるテクノロジに基づきます。 その他は Azure のネイティブのものであり、[Azure Batch](https://docs.microsoft.com/azure/batch?WT.mc_id=riskmodel-docs-scseely)、[Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets?WT.mc_id=riskmodel-docs-scseely)、あるいはカスタム スケーリング ソリューションが使用されます。

この記事では、保険数理開発者が Azure とモデリング パッケージを組み合わせて使用して、リスクを分析する方法を見ていきます。 記事では、Azure での大規模な実行のためにモデリング パッケージで使用される Azure テクノロジをいくつか説明します。 これと同じテクノロジを使用して、ご利用のデータをさらに分析することができます。 ここでは以下の項目について見ていきます。

- Azure における、より短い時間でのより大規模なモデルの実行。
- 結果の報告。
- データ保有期間の管理。

生命、損害、医療など、提供する保険の種類に関係なく、資産と負債の金融およびリスク モデルを作成し、投資と保険料を調整して、保険業者としての支払能力を維持する必要があります。 IFRS 17 レポートでは、契約上のサービス マージン (CSM) の計算など、保険数理士が作成するモデルに変更が加えられています。これにより、保険業者の経時的な利益の管理方法が変わります。

## <a name="running-more-in-less-time-in-azure"></a>Azure における、より短い時間でのより多くの実行

クラウドの可能性を信じてください。金融およびリスク モデルをより迅速かつ簡単に実行することができます。 多くの保険業者では、概算で問題が示されます。これらの計算を最初から最後まで順次行うのに数年、あるいは数十年も要します。 実行時の問題を解決するためのテクノロジが必要です。 戦略は次のとおりです。

- データの準備: 一部のデータは徐々に変化します。 ポリシーまたはサービス契約が実施されると、要求は予測可能なペースで移行します。 データが到着したときにモデルの実行に必要なデータを準備できます。これにより、データのクレンジングと準備のために多くの時間をかける必要がなくなります。 また、クラスタリングを使用して、重み付け表現による連続データの代替を作成することもできます。 通常、レコードの数が減ると、計算時間が短縮されます。
- 並列処理: 2 つ以上の項目に対して同じ分析を行う必要がある場合は、同時に分析できる可能性があります。

これらの項目を個別に見てみましょう。

### <a name="data-preparation"></a>データの準備

データはいくつかの異なるソースから流入します。 業務書には半構造化されたポリシー データがあります。 被保険者、会社、およびさまざまなアプリケーション フォームに表示される項目に関する情報です。 経済シナリオ ジェネレーター (ESG) では、モデルで使用できるフォームへの変換が必要な場合があるさまざまな形式のデータが生成されます。 資産価値に関する現在のデータを正規化する必要もあります。 株式市場データ、レンタルに関するキャッシュ フロー データ、住宅ローンに関する支払情報、およびその他の資産データをすべて、ソースからモデルへの移行時にある程度準備する必要があります。 最後に、最近のエクスペリエンス データに基づいて、前提条件を更新する必要があります。 モデルの実行を高速化するには、事前にデータを準備します。 実行時間が発生したら、最後にスケジュールされた更新後の変更を加えるために必要な更新を行います。

ところで、データはどのように準備するのでしょうか。 まず、一般的な例を見てみましょう。次に、データのさまざまな表示方法をどのように使用するのかを見ていきます。 まず、最後の同期以降に行われた変更をすべて取得するためのメカニズムが必要です。 そのメカニズムでは、並べ替え可能な値を含める必要があります。 最近の変更については、その値が以前の変更のものより大きくなければなりません。 2 つの最も一般的なメカニズムは、増え続ける ID フィールドやタイムスタンプです。 あるレコードの ID キーは増えているが、その他のレコードに更新可能なフィールドが含まれている場合、&quot;last-modified&quot; タイムスタンプなどを使用して、変更を見つける必要があります。 レコードが処理されたら、最後に更新された項目の並べ替え可能な値を記録します。 この値 (おそらく、_lastModified_ というフィールドのタイムスタンプ) は指標になり、データ ストアの後続のクエリで使用されます。 データの変更はさまざまな方法で処理できます。 最小限のリソースを使用する 2 つの一般的なメカニズムを以下に示します。

1. 数百または数千ものプロセス変更がある場合: データを Blob ストレージにアップロードします。 [Azure Data Factory](https://docs.microsoft.com/azure/data-factory?WT.mc_id=riskmodel-docs-scseely) のイベント トリガーを使用して、変更セットを処理します。
2. プロセスの小さな変更セットがあるか、変更が発生したらすぐにデータを更新する場合は、[Service Bus](https://docs.microsoft.com/azure/service-bus-messaging?WT.mc_id=riskmodel-docs-scseely) または[ストレージ キュー](https://docs.microsoft.com/azure/storage/queues/storage-queues-introduction?WT.mc_id=riskmodel-docs-scseely)によってホストされるキュー メッセージに各変更を取り込みます。 2 つのキュー テクノロジ間のトレードオフの詳細については、[こちらの記事](https://docs.microsoft.com/azure/service-bus-messaging/service-bus-azure-and-service-bus-queues-compared-contrasted?WT.mc_id=riskmodel-docs-scseely)を参照してください。 メッセージがキューに取り込まれたら、Azure Functions または Azure Data Factory のトリガーを使用してメッセージを処理できます。

以下の図に一般的なシナリオを示します。 まず、スケジュールされたジョブでいくつかのデータ セットが収集され、ファイルがストレージに配置されます。 スケジュールされたジョブには、オンプレミスで実行される CRON ジョブ、[Scheduler タスク](https://docs.microsoft.com/azure/scheduler?WT.mc_id=riskmodel-docs-scseely)、[Logic App](https://docs.microsoft.com/azure/logic-apps/logic-apps-overview?WT.mc_id=riskmodel-docs-scseely)、タイマーに基づいて実行されるものがあります。 ファイルがアップロードされたら、[Azure 関数](https://docs.microsoft.com/azure/azure-functions?WT.mc_id=riskmodel-docs-scseely)または **Data Factory** のインスタンスをトリガーしてデータを処理できます。 ファイルを短時間で処理できる場合は、**関数**を使用します。 処理が複雑で、AI またはその他の複合スクリプトが必要な場合、[HDInsight](https://docs.microsoft.com/azure/hdinsight?WT.mc_id=riskmodel-docs-scseely)、[Azure Databricks](https://docs.microsoft.com/azure/azure-databricks?WT.mc_id=riskmodel-docs-scseely)、またはカスタマイズされたものが適していることがあります。 完了すると、ファイルは、データベースのレコードとして、または新しいファイルとして使用可能なフォームになります。

 ![](./assets/insurance-risk-assets/process-files.png)

データが Azure に取り込まれたら、モデリング アプリケーションで使用できるようにする必要があります。 コードを書き込んでカスタム変換を行い、項目を **HDInsight** または Azure **Databricks** を介して実行し、より大きな項目を取り込んだり、データを適切なデータ セットにコピーしたりすることができます。 ビッグ データ ツールの使用は、非構造化データから構造化データへの変換や受信データでの AI および ML の実行などにも役立つ場合があります。 また、仮想マシンのホスティング、オンプレミスからデータ ソースへのデータの直接アップロード、Azure Functions の直接呼び出しなどを行うことができます。

後で、データをモデルで使用する必要があります。 これを行う方法は、計算でどのようにデータにアクセスする必要があるかに大きく依存します。 一部のモデリング システムでは、すべてのデータ ファイルが、計算を行うノードに存在する必要があります。 他のシステムでは、[Azure SQL Database](https://docs.microsoft.com/azure/sql-database/?WT.mc_id=riskmodel-docs-scseely)、[MySQL](https://docs.microsoft.com/azure/mysql/?WT.mc_id=riskmodel-docs-scseely)、[PostgreSQL](https://docs.microsoft.com/azure/postgresql/?WT.mc_id=riskmodel-docs-scseely) などのデータベースを利用できます。 これらの項目のいずれかの低コスト バージョンを使用し、モデリングの実行中にパフォーマンスを高めることができます。 これで、日常業務に必要な料金と、数千のコアでデータが要求されるときにだけ必要な追加速度がわかります。 通常、モデリングの実行中はこのデータが読み取り専用になります。 複数のリージョン間で計算を行う場合は、[Cosmos DB](https://docs.microsoft.com/azure/cosmos-db/distribute-data-globally?WT.mc_id=riskmodel-docs-scseely) または [Azure SQL geo レプリケーション](https://docs.microsoft.com/azure/sql-database/sql-database-geo-replication-overview?WT.mc_id=riskmodel-docs-scseely)の使用を検討してください。 これらの両方では、短い待機時間でリージョン間でデータを自動的にレプリケートするためのメカニズムが提供されます。 どちらを選ぶかは、開発者が認識しているツール、データのモデリング方法、モデリングの実行に使用されたリージョンの数によって決まります。

データの格納場所について考える時間を確保します。 同じデータに対して存在する同時要求の数を把握します。 情報を配布する方法について考えます。

- 各コンピューティング ノードで独自のコピーを取得しますか。
- コピーは何らかの高帯域幅の場所を介して共有されますか。

Azure SQL を使用してデータを集中管理し続けるのであれば、ほとんどの場合、より低い価格レベルでデータベースを保持することになります。 データがモデリングの実行時にのみ使用され、めったに更新されない場合、Azure のお客様はデータをバックアップし、実行と実行の間にデータベース インスタンスをオフにすることさえあります。 潜在的な節減額は多くなります。 お客様は [Azure SQL エラスティック プール](https://docs.microsoft.com/azure/sql-database/sql-database-elastic-pool?WT.mc_id=riskmodel-docs-scseely)を利用することもできます。 これらは、特に異なる時間帯に大きな負荷がかかるデータベースを把握していない場合に、データベースのコストを制御するために設計されています。 エラスティック プールでは、一連のデータベースで必要なだけ電力を使用し、システム内の別の場所に需要がシフトしたときにスケールバックできます。

プロセスで後から計算するときに同じデータが使用されるように、モデルの実行時にデータ同期を無効にする必要がある場合があります。 キューを使用する場合は、メッセージ プロセッサを無効にしますが、キューでデータを受信できるようにします。

また、実行前の時間を利用して、経済シナリオを生成し、保険数理の前提条件を更新し、通常は他の静的データを更新することができます。 それでは、経済シナリオ ジェネレーター (ESG) について見てみましょう。 [アクチュアリー協会](https://www.soa.org/)では、米国債利回りをモデリングする ESG である、[Academy Interest Rate Generator](https://www.soa.org/tables-calcs-tools/research-scenario/) (AIRG)  が提供されます。 AIRG は、評価マニュアル 20 (VM-20) 計算などの項目で使用するために規定されています。 他の ESG では、株式市場、住宅ローン、商品価格などをモデリングする場合があります。

ご利用の環境でデータを前処理するため、早い段階で他の部分を実行することもできます。 たとえば、より多くの人口を表すレコードを使用するようにモデリングするとします。 通常、これはレコードをクラスタリングすることで行います。 1 日 1 回など、散発的にデータセットが更新される場合、レコード セットを、取り込みプロセスの一部としてモデルで使用されるものに減らすことができます。

実例を見てましょう。 IFRS-17 を使用して、2 つの契約の開始日の間隔が最長で 1 年未満になるように、契約をまとめてグループ化する必要があります。 これを簡単な方法で行い、グループ化メカニズムとして契約年を使用するとします。 このセグメント化は、ファイルに目を通し、レコードを適切な年グループに移動することで、データが Azure に読み込まれる間に行うことができます。

データの準備に重点を置くことで、モデル コンポーネントの実行に必要な時間が短縮されます。 早い段階でデータを取得することで、モデルの実行時間を節約できます。

### <a name="parallelization"></a>並列処理

ステップの適切な並列処理により、実行時間 (クロック時間) を大幅に短縮できます。 この高速化は、実装する部分を効率化し、2 つ以上のアクティビティを同時に実行できる方法でモデルを表現する方法を把握することで実現できます。 その際のこつは、作業要求のサイズと、個々のノードの生産性との間のバランスを見つけることです。 タスクで評価よりセットアップとクリーンアップに長い時間がかかる場合、小さすぎます。 タスクが大きすぎる場合、実行時間は改善されません。 アクティビティを、複数のノードに分散させ、実行経過時間に効果が見られるくらい十分小さくする必要があります。

システムを最大限に活用するには、モデルのワークフローと、計算でスケールアウトの機能を操作する方法を理解する必要があります。ソフトウェアにはジョブやタスクなどの概念がある場合があります。 その知識を活かして、作業を分割できるものを設計します。 モデルにいくつかのカスタム ステップがある場合は、入力をより小さい処理グループに分割できるように設計します。 多くの場合、これをスキャッター/ギャザー パターンといいます。

- スキャッター: 自然な線に沿って入力を分割し、個別のタスクを実行できるようにします。
- ギャザー: タスクが完了したときに、それらの出力を収集します。

また、分割時に、プロセスを同期する必要がある場所を確認してから先に進みます。 一般的な分割場所はいくつかあります。 入れ子になった確率的実行の場合、100 個のシナリオの内部ループを実行する一連の変曲点がある 1,000 個の外部ループが存在する場合があります。 各外部ループは同時に実行できます。 変曲点で止め、内部ループを同時に実行し、外部ループ用にデータを調整するために情報を戻し、再び先に進みます。 次の図にワークフローを示します。 十分なコンピューティングであれば、100,000 個のコアで 100,000 個の内部ループを実行でき、処理時間は次の時間の合計になります。

![](./assets/insurance-risk-assets/timing.png)

方法に応じて、配布は若干増えます。つまり、適切なパラメーターを指定した小さなジョブを作成するだけのシンプルなものになる場合や、適切な場所に 100K ファイルをコピーするくらい複雑なものになる場合があります。 HD Insight の Apache Spark、Azure Databricks、または独自のデプロイ環境を使用して結果集計を配布できる場合は、結果の処理をさらに高速化できます。 たとえば、平均の計算は、これまでの項目数と合計を記憶しておくだけの簡単な処理です。 その他の計算は、数千個のコアを備えた単一コンピューターに適している場合があります。 その場合、Azure で GPU 対応のコンピューターを利用できます。

ほとんどの保険数理チームは、モデルを Azure に移行することから開始します。 その後、プロセスにおけるさまざまなステップに関するタイミング データを収集します。 次に、最長経過時間から最短経過時間までのステップごとのクロック時間を並べ替えます。 数千のコア時間が使用される可能性はあるが、経過時間が 20 分のみであるため、総実行時間は確認しません。 最も長く実行されている各ジョブ ステップについては、保険数理開発者は、正しい結果を得ながら、経過時間を減らす方法を模索します。 このプロセスは定期的に繰り返されます。 一部の保険数理チームではターゲットの実行時間を設定します。つまり、夜間のヘッジ分析を 8 時間未満で行うことが目標となります。 この時間が 8.25 時間に近づくとすぐに、保険数理チームの一部が、分析の最も長い部分の時間を改善するために切り替えられます。 時間が 7.5 時間未満に戻った場合、開発に戻ります。 元に戻り、最適化するためのヒューリスティックは保険数理士によって異なります。

これをすべて実行するための、いくつかのオプションがあります。 ほとんどの保険数理ソフトウェアは、コンピューティング グリッドで動作します。 オンプレミスおよび Azure で動作するグリッドでは、[HPC Pack](https://docs.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options?WT.mc_id=riskmodel-docs-scseely)、サード パーティのパッケージ、またはカスタマイズされたものが使用されます。 Azure 用に最適化されたグリッドでは、[Virtual Machine Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/?WT.mc_id=riskmodel-docs-scseely)、[Batch](https://docs.microsoft.com/azure/batch/?WT.mc_id=riskmodel-docs-scseely)、またはカスタマイズされたものが使用されます。 Scale Sets または Batch を使用することにした場合は、必ず、低優先度 VM のサポート ([Scale Sets](https://docs.microsoft.com/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-use-low-priority?WT.mc_id=riskmodel-docs-scseely) の低優先度に関するドキュメント、[Batch](https://docs.microsoft.com/azure/batch/batch-low-pri-vms?WT.mc_id=riskmodel-docs-scseely) の低優先度に関するドキュメント) を確認してください。 低優先度 VM とは、通常価格の何分の 1 かでレンタルできる、ハードウェアで実行される VM のことです。 低優先度 VM は容量要求時に割り込まれる可能性があるため、より低価格で利用できます。 時間予算にある程度余裕がある場合、低優先度 VM では、モデリングの実行の価格を下げるための優れた方法が提供されます。

多くのコンピューター (おそらく、さなざまなリージョンで実行されているものを含む) で実行およびデプロイを調整する必要がある場合、CycleCloud を利用できます。 CycleCloud では追加コストは発生しません。 必要に応じて、データ移動が調整されます。 これには、コンピューターの割り当て、監視、シャットダウンが含まれます。 低優先度コンピューターを処理することもでき、確実にその費用は含まれます。 必要なコンピューターの組み合わせを説明することさえできます。 たとえば、おそらくコンピューター クラスが必要ですが、2 つ以上のコアを備えた任意のバージョンでも正常に実行できます。 Cycle ではこれらのコンピューターの種類でコアを割り当てることができます。

## <a name="reporting-on-the-results"></a>結果の報告

保険数理パッケージが実行され、その結果が生成されたら、いくつかの規制レポートが準備できています。 規制者や監査員が必要としない分析情報を生成するために分析できる新しいデータも山ほどあります。 最適な顧客のプロファイルを理解することができます。 分析情報を使用して、低コスト顧客がどのようなものであるかをマーケティング部に伝え、マーケティング部と販売部でそれらをより早く見つけられるようにします。 同様に、データを使用して、保険に加入することで最も利益が得られるグループを見つけることができます。 たとえば、初期段階の健康問題をより早く発見できる年に一度の身体検査を利用する人が見つかる場合があります。 これにより、保険会社の時間とコストが節約されます。 そのデータを使用して、顧客ベースの行動を駆り立てることができます。

これを行うには、多くのデータ サイエンス ツールと、視覚化のための一部のデータへのアクセスが必要です。 どの程度の調査を行うかに応じて、[データ サイエンス VM](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview?WT.mc_id=riskmodel-docs-scseely) から開始できます。この VM は Azure Marketplace からプロビジョニングできます。 これらの VM には、Windows 版と Linux 版の両方があります。 インストールしたら、Microsoft R Open、Microsoft ML Server、Anaconda、Jupyter、およびその他のツールの準備が整います。 R または Python を少し挿入して、データを視覚化し、同僚と分析情報を共有します。

さらに分析を行う必要がある場合は、HDInsight または Databricks を介して、Spark や Hadoop などの Apache データ サイエンス ツールを使用できます。 分析を定期的に行う必要があり、ワークフローを自動化する場合にもこれらを使用します。 これは、大規模なデータセットのライブ分析にも役立ちます。

何か興味深いものが見つかったら、結果を示す必要があります。 多くの保険数理士は、まず、サンプルの結果を使用し、Excel に取り込んでチャート、グラフ、およびその他の視覚エフェクトを作成します。 データを詳しく調べるのに適したインターフェイスを備えたものが必要な場合は、[Power BI](https://docs.microsoft.com/power-bi/?WT.mc_id=riskmodel-docs-scseely) を確認してください。 Power BI ではいくつかの適した視覚エフェクトを作成し、ソース データを表示できます。また、[順序付けられ、注釈の付いたブックマーク](https://docs.microsoft.com/power-bi/desktop-bookmarks?WT.mc_id=riskmodel-docs-scseely)を追加することで、閲覧者にデータを説明することができます。

## <a name="data-retention"></a>データ保有期間

システムに取り込むデータの多くは、将来の監査のために保持する必要があります。 データ保有期間要件の範囲は、通常、7 年から 10 年ですが、この要件は変わります。 最小保有期間の対象は以下のとおりです。

- モデルへの元の入力のスナップショット。 これには資産、負債、前提条件、ESG、およびその他の入力が含まれます。
- 最終的な出力のスナップショット。 これには、規制機関に提示するレポートを作成するために使用されたすべてのデータが含まれます。
- その他の重要な中間結果。 監査員は、モデルで何らかの結果が得られた理由をたずねます。 モデルである選択を行った、あるいは特定の数値が得られた理由に関する証拠を保持する必要があります。 多くの保険業者は、元の入力から最終出力を生成するために使用されたバイナリを保持することを選択します。 その後、たずねられたときに、モデルを再実行し、中間結果の最新コピーを取得します。 出力が一致した場合、中間ファイルに必要な説明も含める必要があります。

モデルの実行中に、保険数理士は、実行からの要求負荷を処理できるデータ配信メカニズムを使用します。 実行が完了し、データが不要になったら、データの一部を保持します。 少なくとも、保険業者は、再現性要件の実行時構成と入力を保持する必要があります。 データベースは Azure Blob Storage 内のバックアップに保持され、サーバーはシャットダウンされます。 高速ストレージ上のデータも、より低コストの Azure Blob Storage に移行されます。 Blob Storage に移行されたら、各 BLOB で使用するデータ層 (ホット、クール、アーカイブ) を選択できます。 ホット ストレージは、頻繁にアクセスされるファイルに適しています。 クール ストレージは、頻度の低いデータ アクセス用に最適化されています。 アーカイブ ストレージは監査可能なファイルを保持するのに最適です。しかし、価格の割引により待機時間コストが発生します。アーカイブ層のデータ待機時間は時間単位で測定されます。 [Azure Blob Storage: ホット、クール、アーカイブ ストレージ層](https://docs.microsoft.com/azure/storage/blobs/storage-blob-storage-tiers?WT.mc_id=riskmodel-docs-scseely)に関するページをお読みになり、さまざまなストレージ層についてよく理解してください。 ライフサイクル管理により、データを作成して削除するまでの管理を行うことができます。 BLOB の URI はそのままですが、BLOB の格納場所については、時間の経過と共にコストが低くなります。 この機能により、Azure Storage の多くのユーザーはコストを大幅に節約でき、頭痛の種を取り除くことができます。 [Azure Blob Storage のライフサイクルの管理](https://docs.microsoft.com/azure/storage/common/storage-lifecycle-managment-concepts?WT.mc_id=riskmodel-docs-scseely)に関するページで、入力と出力について学習できます。 自動的にファイルを削除できるのはすばらしいことです。つまり、ファイル自体を自動的に削除できるため、スコープ外のファイルを参照し、誤って監査を拡張することがなくなります。

## <a name="next-steps"></a>次の手順

実行する保険数理システムにオンプレミス グリッドの実装がある場合、そのグリッドの実装は Azure でも実行される可能性があります。 一部のベンダーでは、ハイパースケールで実行される Azure 実装が特殊化されています。 Azure への移行時に、内部ツールも移行します。 どこの保険数理士も、データ サイエンス スキルがラップトップや大規模な環境に適していることに気付いています。 チームで既に行ったものを見つけます。おそらく、ディープ ラーニングを使用するが、1 つの GPU で実行するのに数時間または数日かかるものです。 4 つのハイエンド GPU を備えたコンピューター上で同じワークロードを実行してみて、実行時間を確認します。既存のものであれば、大幅な高速化となる可能性は十分あります。

改善されたら、必ず、データ同期を構築し、モデリング データのフィードも行ってください。 データが準備できるまで、モデルの実行を開始することはできません。 変更されたデータのみを送信するために、多少の手間がかかる場合があります。 実際の方法は、データ サイズにも依存します。つまり、数 MB の更新はおそらくたいしたことではありませんが、数ギガバイトのアップロードを減らすことは大幅な高速化になります。

### <a name="tutorials"></a>チュートリアル

- R 開発者:[Azure Batch での並列 R シミュレーションの実行](https://docs.microsoft.com/azure/batch/tutorial-r-doazureparallel?WT.mc_id=riskmodel-docs-scseely)
- Azure 関数を使用して、ストレージを操作する方法を示すチュートリアル: [Azure Functions を使用して Blob Storage に画像をアップロードする](https://docs.microsoft.com/azure/functions/tutorial-static-website-serverless-api-with-database?tutorial-step=2&WT.mc_id=riskmodel-docs-scseely)
- Databricks を使用する ETL: [Azure Databricks を使用したデータの抽出、変換、読み込み](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse?WT.mc_id=riskmodel-docs-scseely)
- HDInsight を使用する ETL: [Azure HDInsight の Apache Hive を使用したデータの抽出、変換、読み込み](https://docs.microsoft.com/azure/hdinsight/hdinsight-analyze-flight-delay-data-linux?toc=%2Fen-us%2Fazure%2Fhdinsight%2Fhadoop%2FTOC.json&amp;bc=%2Fen-us%2Fazure%2Fbread%2Ftoc.json&WT.mc_id=riskmodel-docs-scseely)
- データ サイエンス VM の使用方法 (Linux): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/linux-dsvm-walkthrough?WT.mc_id=riskmodel-docs-scseely)
- データ サイエンス VM の使用方法 (Windows): [https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/vm-do-ten-things?WT.mc_id=riskmodel-docs-scseely)
